{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Modelo LSTM\n",
    "3 colunas\n",
    "pytorch\n",
    "bayesian optimization"
   ],
   "id": "3d3a70a7a3d2c88a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T23:04:42.331436Z",
     "start_time": "2024-08-19T23:04:42.326892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Categorical, Real\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n"
   ],
   "id": "d14921d7ecd62577",
   "outputs": [],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T23:04:42.348026Z",
     "start_time": "2024-08-19T23:04:42.341509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device}')"
   ],
   "id": "a923c34ab535636f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T23:04:42.399788Z",
     "start_time": "2024-08-19T23:04:42.397083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cria pasta de logs com data de hoje\n",
    "\n",
    "data_hoje = datetime.now().strftime('%d-%m')\n",
    "os.makedirs(f'../logs/{data_hoje}', exist_ok=True)\n",
    "os.makedirs(f'../plots/{data_hoje}', exist_ok=True)"
   ],
   "id": "d8b9a719f4528b69",
   "outputs": [],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T23:04:42.450583Z",
     "start_time": "2024-08-19T23:04:42.447367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "\n",
    "inicio_execucao = pd.Timestamp.now()\n",
    "\n",
    "logging.basicConfig(filename=f'../logs/{data_hoje}/lstm.log', level=logging.INFO, format='- %(message)s')\n",
    "logging.info('-' * 50)\n",
    "logging.info(f'{inicio_execucao} - Iniciando o processo de treinamento do modelo LSTM')"
   ],
   "id": "7f1eda578a581056",
   "outputs": [],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T23:04:42.664685Z",
     "start_time": "2024-08-19T23:04:42.495819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_original = pd.read_csv('../dados_tratados/combinado/Piratininga/Piratininga_tratado_combinado.csv',\n",
    "                          usecols=['PM2.5', 'Data e Hora', 'PM10', 'Mon贸xido de Carbono'], low_memory=False)"
   ],
   "id": "171955d3a27b508c",
   "outputs": [],
   "execution_count": 189
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T23:04:42.792784Z",
     "start_time": "2024-08-19T23:04:42.711942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_original['Data e Hora'] = pd.to_datetime(df_original['Data e Hora'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_original.index = df_original['Data e Hora']\n",
    "df_original.sort_index(inplace=True)\n",
    "\n",
    "colunas_selecionadas = ['PM2.5', 'PM10', 'Mon贸xido de Carbono']\n",
    "df = df_original[colunas_selecionadas]\n",
    "\n",
    "df = df.loc['2019-01-01':'2022-01-01']\n",
    "\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "logging.info(f'Colunas Selecionadas: {colunas_selecionadas}')\n",
    "df.head(20)"
   ],
   "id": "d711b48520899f06",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     PM2.5   PM10  Mon贸xido de Carbono\n",
       "Data e Hora                                           \n",
       "2019-01-01 00:30:00   37.0  45.12                 0.77\n",
       "2019-01-01 01:30:00   23.0  70.53                 0.92\n",
       "2019-01-01 02:30:00   18.0  68.99                 0.81\n",
       "2019-01-01 03:30:00   13.0  59.54                 0.57\n",
       "2019-01-01 04:30:00    7.0  30.84                 0.44\n",
       "2019-01-01 05:30:00    2.0  17.32                 0.43\n",
       "2019-01-01 06:30:00    NaN   8.84                 0.40\n",
       "2019-01-01 07:30:00    NaN  16.81                 0.41\n",
       "2019-01-01 08:30:00    NaN   9.08                 0.41\n",
       "2019-01-01 09:30:00    1.0   6.37                 0.42\n",
       "2019-01-01 10:30:00    NaN   3.86                 0.44\n",
       "2019-01-01 11:30:00    4.0  10.94                 0.47\n",
       "2019-01-01 12:30:00    NaN    NaN                 0.48\n",
       "2019-01-01 13:30:00    7.0  18.47                 0.42\n",
       "2019-01-01 14:30:00    5.0  24.14                 0.42\n",
       "2019-01-01 15:30:00    8.0  12.46                 0.50\n",
       "2019-01-01 16:30:00    NaN    NaN                 0.50\n",
       "2019-01-01 17:30:00    NaN    NaN                 0.53\n",
       "2019-01-01 18:30:00   11.0  19.50                 0.63\n",
       "2019-01-01 19:30:00    8.0  28.40                 0.60"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>Mon贸xido de Carbono</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data e Hora</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:30:00</th>\n",
       "      <td>37.0</td>\n",
       "      <td>45.12</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:30:00</th>\n",
       "      <td>23.0</td>\n",
       "      <td>70.53</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:30:00</th>\n",
       "      <td>18.0</td>\n",
       "      <td>68.99</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:30:00</th>\n",
       "      <td>13.0</td>\n",
       "      <td>59.54</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 04:30:00</th>\n",
       "      <td>7.0</td>\n",
       "      <td>30.84</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 05:30:00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>17.32</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 06:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.84</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 07:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16.81</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 08:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:30:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.37</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 10:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.86</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 11:30:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10.94</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 12:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 13:30:00</th>\n",
       "      <td>7.0</td>\n",
       "      <td>18.47</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 14:30:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>24.14</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 15:30:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>12.46</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 16:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 17:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 18:30:00</th>\n",
       "      <td>11.0</td>\n",
       "      <td>19.50</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 19:30:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>28.40</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T23:04:42.875754Z",
     "start_time": "2024-08-19T23:04:42.868857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def impute_missing_values(df):\n",
    "    return df.interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "\n",
    "df_imputed = impute_missing_values(df)\n",
    "\n",
    "logging.info(f\"Dados ausentes antes da imputa莽茫o: {df.isna().sum()}\")\n",
    "logging.info(f\"Dados ausentes ap贸s a imputa莽茫o: {df_imputed.isna().sum()}\")"
   ],
   "id": "cf71a13126091c0e",
   "outputs": [],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T23:04:42.931974Z",
     "start_time": "2024-08-19T23:04:42.910296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from copy import deepcopy as dc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Preparando os dados para LSTM\n",
    "def prepare_dataframe_for_lstm(df, n_steps):\n",
    "    df = dc(df)\n",
    "    for col in colunas_selecionadas:\n",
    "        for i in range(1, n_steps + 1):\n",
    "            df[f'{col}(t-{i})'] = df[col].shift(i)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "lookback = 8  # 8 horas de lookback\n",
    "shifted_df = prepare_dataframe_for_lstm(df_imputed, lookback)\n",
    "\n",
    "# Normalizando os dados\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "shifted_df_as_np = scaler.fit_transform(shifted_df)\n",
    "\n",
    "X = shifted_df_as_np[:, len(colunas_selecionadas):]\n",
    "y = shifted_df_as_np[:, 0]  # Mantemos PM2.5 como nossa vari谩vel alvo\n",
    "\n",
    "X = dc(np.flip(X, axis=1))\n",
    "\n",
    "# Dividindo em conjuntos de treino, valida莽茫o e teste\n",
    "train_split = int(len(X) * 0.7)\n",
    "val_split = int(len(X) * 0.85)\n",
    "\n",
    "X_train, X_val, X_test = X[:train_split], X[train_split:val_split], X[val_split:]\n",
    "y_train, y_val, y_test = y[:train_split], y[train_split:val_split], y[val_split:]\n"
   ],
   "id": "d5fef927653f6d40",
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T23:04:42.959871Z",
     "start_time": "2024-08-19T23:04:42.955446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, input_size)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Inicialize hidden state com zeros\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        # Inicialize cell state\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Decodifique o 煤ltimo estado oculto\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ],
   "id": "8a440926fb29a7ed",
   "outputs": [],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T23:04:43.025579Z",
     "start_time": "2024-08-19T23:04:43.021355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch.unsqueeze(1))\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            logging.info(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    return train_losses, val_losses"
   ],
   "id": "329eddfabbe3499",
   "outputs": [],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T23:04:43.073656Z",
     "start_time": "2024-08-19T23:04:43.068239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Definindo o espa莽o de busca para o otimizador bayesiano\n",
    "search_space = {\n",
    "    'hidden_size': Integer(32, 256),\n",
    "    'num_layers': Integer(1, 3),\n",
    "    'dropout': Real(0.0, 0.5),\n",
    "    'learning_rate': Real(1e-4, 1e-2, prior='log-uniform'),\n",
    "    'batch_size': Categorical([32, 64, 128])\n",
    "}\n"
   ],
   "id": "2174a6400590df92",
   "outputs": [],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T23:04:43.121856Z",
     "start_time": "2024-08-19T23:04:43.115761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def objective(**params):\n",
    "    hidden_size = int(params['hidden_size'])\n",
    "    num_layers = int(params['num_layers'])\n",
    "    dropout = params['dropout']\n",
    "    learning_rate = params['learning_rate']\n",
    "    batch_size = int(params['batch_size'])\n",
    "    \n",
    "    model = LSTM(input_size=X_train.shape[1], hidden_size=hidden_size, num_layers=num_layers, \n",
    "                 output_size=1, dropout=dropout).to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Reformatar os dados para (batch_size, sequence_length, input_size)\n",
    "    X_train_reshaped = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "    X_val_reshaped = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "    \n",
    "    train_dataset = TensorDataset(torch.FloatTensor(X_train_reshaped), torch.FloatTensor(y_train))\n",
    "    val_dataset = TensorDataset(torch.FloatTensor(X_val_reshaped), torch.FloatTensor(y_val))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    _, val_losses = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50)\n",
    "    \n",
    "    return -val_losses[-1]  # Retorna o negativo da perda de valida莽茫o final (queremos maximizar)\n",
    "\n",
    "# Definindo o espa莽o de busca para o otimizador bayesiano\n",
    "pbounds = {\n",
    "    'hidden_size': (32, 256),\n",
    "    'num_layers': (1, 3),\n",
    "    'dropout': (0.0, 0.5),\n",
    "    'learning_rate': (1e-4, 1e-2),\n",
    "    'batch_size': (32, 128)\n",
    "}\n"
   ],
   "id": "ee72f207ad8370fd",
   "outputs": [],
   "execution_count": 196
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T23:17:21.829032Z",
     "start_time": "2024-08-19T23:04:43.169524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "# Executando a otimiza莽茫o bayesiana\n",
    "optimizer = BayesianOptimization(\n",
    "    f=objective,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(\n",
    "    init_points=5,\n",
    "    n_iter=45,\n",
    ")\n",
    "\n",
    "# Registrando os melhores par芒metros encontrados\n",
    "best_params = optimizer.max['params']\n",
    "logging.info(f\"Melhores par芒metros encontrados: {best_params}\")\n",
    "logging.info(f\"Melhor pontua莽茫o: {-optimizer.max['target']}\")  # Note o sinal negativo aqui\n",
    "\n",
    "# Ajustando os tipos de dados dos melhores par芒metros\n",
    "best_params['hidden_size'] = int(best_params['hidden_size'])\n",
    "best_params['num_layers'] = int(best_params['num_layers'])\n",
    "best_params['batch_size'] = int(best_params['batch_size'])\n",
    "\n",
    "# Treinando o modelo final com os melhores par芒metros\n",
    "final_model = LSTM(input_size=X_train.shape[1], hidden_size=best_params['hidden_size'], \n",
    "                   num_layers=best_params['num_layers'], output_size=1, \n",
    "                   dropout=best_params['dropout']).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n",
    "\n",
    "train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=best_params['batch_size'])\n",
    "\n",
    "train_losses, val_losses = train_model(final_model, train_loader, val_loader, criterion, optimizer, num_epochs=100)"
   ],
   "id": "21cc21606875fb08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... |  dropout  | hidden... | learni... | num_la... |\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.36016224672107905 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001B[39m1        \u001B[39m | \u001B[39m-0.001305\u001B[39m | \u001B[39m72.03    \u001B[39m | \u001B[39m0.3602   \u001B[39m | \u001B[39m32.03    \u001B[39m | \u001B[39m0.003093 \u001B[39m | \u001B[39m1.294    \u001B[39m |\n",
      "| \u001B[35m2        \u001B[39m | \u001B[35m-0.001301\u001B[39m | \u001B[35m40.86    \u001B[39m | \u001B[35m0.09313  \u001B[39m | \u001B[35m109.4    \u001B[39m | \u001B[35m0.004028 \u001B[39m | \u001B[35m2.078    \u001B[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.34260975019837975 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001B[39m3        \u001B[39m | \u001B[39m-0.001334\u001B[39m | \u001B[39m72.24    \u001B[39m | \u001B[39m0.3426   \u001B[39m | \u001B[39m77.8     \u001B[39m | \u001B[39m0.008793 \u001B[39m | \u001B[39m1.055    \u001B[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.20865240118356349 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001B[35m4        \u001B[39m | \u001B[35m-0.001274\u001B[39m | \u001B[35m96.36    \u001B[39m | \u001B[35m0.2087   \u001B[39m | \u001B[35m157.1    \u001B[39m | \u001B[35m0.00149  \u001B[39m | \u001B[35m1.396    \u001B[39m |\n",
      "| \u001B[39m5        \u001B[39m | \u001B[39m-0.001311\u001B[39m | \u001B[39m108.9    \u001B[39m | \u001B[39m0.4841   \u001B[39m | \u001B[39m102.2    \u001B[39m | \u001B[39m0.006954 \u001B[39m | \u001B[39m2.753    \u001B[39m |\n",
      "| \u001B[39m6        \u001B[39m | \u001B[39m-0.001319\u001B[39m | \u001B[39m97.13    \u001B[39m | \u001B[39m0.3437   \u001B[39m | \u001B[39m157.8    \u001B[39m | \u001B[39m0.003645 \u001B[39m | \u001B[39m2.226    \u001B[39m |\n",
      "| \u001B[39m7        \u001B[39m | \u001B[39m-0.001297\u001B[39m | \u001B[39m114.7    \u001B[39m | \u001B[39m0.1895   \u001B[39m | \u001B[39m122.3    \u001B[39m | \u001B[39m0.003854 \u001B[39m | \u001B[39m2.007    \u001B[39m |\n",
      "| \u001B[35m8        \u001B[39m | \u001B[35m-0.001262\u001B[39m | \u001B[35m73.12    \u001B[39m | \u001B[35m0.2821   \u001B[39m | \u001B[35m242.0    \u001B[39m | \u001B[35m0.00446  \u001B[39m | \u001B[35m2.438    \u001B[39m |\n",
      "| \u001B[39m9        \u001B[39m | \u001B[39m-0.001271\u001B[39m | \u001B[39m73.12    \u001B[39m | \u001B[39m0.2838   \u001B[39m | \u001B[39m242.0    \u001B[39m | \u001B[39m0.006101 \u001B[39m | \u001B[39m2.44     \u001B[39m |\n",
      "| \u001B[39m10       \u001B[39m | \u001B[39m-0.001284\u001B[39m | \u001B[39m73.11    \u001B[39m | \u001B[39m0.2765   \u001B[39m | \u001B[39m242.0    \u001B[39m | \u001B[39m0.0001   \u001B[39m | \u001B[39m2.433    \u001B[39m |\n",
      "| \u001B[39m11       \u001B[39m | \u001B[39m-0.00128 \u001B[39m | \u001B[39m73.12    \u001B[39m | \u001B[39m0.2834   \u001B[39m | \u001B[39m242.0    \u001B[39m | \u001B[39m0.0001   \u001B[39m | \u001B[39m2.44     \u001B[39m |\n",
      "| \u001B[39m12       \u001B[39m | \u001B[39m-0.001264\u001B[39m | \u001B[39m73.11    \u001B[39m | \u001B[39m0.2793   \u001B[39m | \u001B[39m242.0    \u001B[39m | \u001B[39m0.01     \u001B[39m | \u001B[39m2.435    \u001B[39m |\n",
      "| \u001B[39m13       \u001B[39m | \u001B[39m-0.001316\u001B[39m | \u001B[39m120.2    \u001B[39m | \u001B[39m0.3022   \u001B[39m | \u001B[39m144.0    \u001B[39m | \u001B[39m0.004184 \u001B[39m | \u001B[39m2.862    \u001B[39m |\n",
      "| \u001B[39m14       \u001B[39m | \u001B[39m-0.001311\u001B[39m | \u001B[39m32.48    \u001B[39m | \u001B[39m0.1346   \u001B[39m | \u001B[39m156.6    \u001B[39m | \u001B[39m0.009566 \u001B[39m | \u001B[39m2.806    \u001B[39m |\n",
      "| \u001B[39m15       \u001B[39m | \u001B[39m-0.001268\u001B[39m | \u001B[39m73.1     \u001B[39m | \u001B[39m0.2605   \u001B[39m | \u001B[39m242.0    \u001B[39m | \u001B[39m0.01     \u001B[39m | \u001B[39m2.419    \u001B[39m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[197], line 9\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# Executando a otimiza莽茫o bayesiana\u001B[39;00m\n\u001B[0;32m      3\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m BayesianOptimization(\n\u001B[0;32m      4\u001B[0m     f\u001B[38;5;241m=\u001B[39mobjective,\n\u001B[0;32m      5\u001B[0m     pbounds\u001B[38;5;241m=\u001B[39mpbounds,\n\u001B[0;32m      6\u001B[0m     random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m      7\u001B[0m )\n\u001B[1;32m----> 9\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43minit_points\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m45\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# Registrando os melhores par芒metros encontrados\u001B[39;00m\n\u001B[0;32m     15\u001B[0m best_params \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mmax[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:374\u001B[0m, in \u001B[0;36mBayesianOptimization.maximize\u001B[1;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001B[0m\n\u001B[0;32m    372\u001B[0m     x_probe \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msuggest(util)\n\u001B[0;32m    373\u001B[0m     iteration \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 374\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprobe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_probe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlazy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bounds_transformer \u001B[38;5;129;01mand\u001B[39;00m iteration \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    377\u001B[0m     \u001B[38;5;66;03m# The bounds transformer should only modify the bounds after\u001B[39;00m\n\u001B[0;32m    378\u001B[0m     \u001B[38;5;66;03m# the init_points points (only for the true iterations)\u001B[39;00m\n\u001B[0;32m    379\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_bounds(\n\u001B[0;32m    380\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bounds_transformer\u001B[38;5;241m.\u001B[39mtransform(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_space))\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:245\u001B[0m, in \u001B[0;36mBayesianOptimization.probe\u001B[1;34m(self, params, lazy)\u001B[0m\n\u001B[0;32m    243\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_queue\u001B[38;5;241m.\u001B[39madd(params)\n\u001B[0;32m    244\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 245\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_space\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprobe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    246\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch(Events\u001B[38;5;241m.\u001B[39mOPTIMIZATION_STEP)\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\bayes_opt\\target_space.py:373\u001B[0m, in \u001B[0;36mTargetSpace.probe\u001B[1;34m(self, params)\u001B[0m\n\u001B[0;32m    370\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cache[_hashable(x\u001B[38;5;241m.\u001B[39mravel())]\n\u001B[0;32m    372\u001B[0m params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_keys, x))\n\u001B[1;32m--> 373\u001B[0m target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    375\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constraint \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    376\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregister(x, target)\n",
      "Cell \u001B[1;32mIn[196], line 24\u001B[0m, in \u001B[0;36mobjective\u001B[1;34m(**params)\u001B[0m\n\u001B[0;32m     21\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m DataLoader(train_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     22\u001B[0m val_loader \u001B[38;5;241m=\u001B[39m DataLoader(val_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size)\n\u001B[1;32m---> 24\u001B[0m _, val_losses \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39mval_losses[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "Cell \u001B[1;32mIn[194], line 13\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs)\u001B[0m\n\u001B[0;32m     11\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(X_batch)\n\u001B[0;32m     12\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, y_batch\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m---> 13\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     15\u001B[0m train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    524\u001B[0m     )\n\u001B[1;32m--> 525\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 267\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    745\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    746\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 197
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
