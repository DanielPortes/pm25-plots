{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T03:53:06.527845Z",
     "start_time": "2024-07-14T03:53:06.524650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ],
   "id": "d14921d7ecd62577",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T03:53:06.722235Z",
     "start_time": "2024-07-14T03:53:06.531850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device}')\n",
    "\n",
    "df = pd.read_csv('../dados_tratados/combinado/Piratininga/Piratininga_tratado_combinado.csv',\n",
    "                 usecols=['PM2.5', 'Data e Hora'])\n",
    "df.dropna(inplace=True)\n",
    "df.index = pd.to_datetime(df['Data e Hora'], format='%Y-%m-%d %H:%M:%S')\n",
    "train_dates = pd.to_datetime(df['Data e Hora'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df['Data e Hora'] = pd.to_datetime(df['Data e Hora'])\n",
    "\n",
    "# df['hour'] = df['Data e Hora'].dt.hour\n",
    "# df['minute'] = df['Data e Hora'].dt.minute\n",
    "# df['year'] = df['Data e Hora'].dt.year\n",
    "# df['month'] = df['Data e Hora'].dt.month\n",
    "# df['day'] = df['Data e Hora'].dt.day\n",
    "# df['day_of_week'] = df['Data e Hora'].dt.dayofweek\n",
    "# df['day_of_year'] = df['Data e Hora'].dt.dayofyear\n",
    "# df['week'] = df['Data e Hora'].dt.isocalendar().week\n",
    "\n",
    "df.drop('Data e Hora', axis=1, inplace=True)\n",
    "\n"
   ],
   "id": "fda3343bbafcd43e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T03:53:06.810499Z",
     "start_time": "2024-07-14T03:53:06.723240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Normalizando os dados de PM2.5\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_values = scaler.fit_transform(df['PM2.5'].values.reshape(-1, 1))\n",
    "\n",
    "df['PM2.5'] = scaled_values\n",
    "\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data) - seq_length - 1):\n",
    "        x = data[i:(i + seq_length)].astype(np.float32)\n",
    "        y = data[i + seq_length, 0]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "\n",
    "seq_length = 8\n",
    "X, y = create_sequences(df.values, seq_length)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float().reshape(-1, 1)\n",
    "X_val = torch.from_numpy(X_val).float()\n",
    "y_val = torch.from_numpy(y_val).float().reshape(-1, 1)\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).float().reshape(-1, 1)\n",
    "\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "val_data = TensorDataset(X_val, y_val)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ],
   "id": "4011bc3253703272",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T03:53:06.814593Z",
     "start_time": "2024-07-14T03:53:06.811505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# class LSTM(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_layer_size, num_layers, output_size, drop_prob=0.2):\n",
    "#         super(LSTM, self).__init__()\n",
    "#         self.hidden_layer_size = hidden_layer_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers, batch_first=True)\n",
    "#         self.dropout = nn.Dropout(drop_prob)\n",
    "#         self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "# \n",
    "#     def forward(self, input_seq):\n",
    "#         lstm_out, _ = self.lstm(input_seq)\n",
    "#         predictions = self.linear(lstm_out[:, -1, :])\n",
    "#         return predictions\n",
    "# \n",
    "# \n",
    "# input_size = X_train.shape[2]\n",
    "# model = LSTM(input_size=input_size, hidden_layer_size=512, num_layers=2, output_size=1).to(device)\n",
    "# loss_function = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "# \n",
    "# \n",
    "# def train_model(model, train_loader, val_loader, loss_function, optimizer, epochs=150, patience=10):\n",
    "#     train_losses = []\n",
    "#     val_losses = []\n",
    "#     best_val_loss = np.inf\n",
    "#     counter = 0\n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()\n",
    "#         train_loss = 0.0\n",
    "#         # Loop de treinamento\n",
    "#         for seq, labels in train_loader:\n",
    "#             seq, labels = seq.to(device), labels.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             y_pred = model(seq)\n",
    "#             single_loss = loss_function(y_pred, labels)\n",
    "#             single_loss.backward()\n",
    "#             optimizer.step()\n",
    "#             train_loss += single_loss.item() * seq.size(0)\n",
    "# \n",
    "#         train_loss /= len(train_loader.dataset)\n",
    "#         train_losses.append(train_loss)\n",
    "# \n",
    "#         model.eval()\n",
    "#         val_loss = 0.0\n",
    "#         # Loop de validação\n",
    "#         with torch.no_grad():\n",
    "#             for seq, labels in val_loader:\n",
    "#                 seq, labels = seq.to(device), labels.to(device)\n",
    "#                 y_pred = model(seq)\n",
    "#                 single_loss = loss_function(y_pred, labels)\n",
    "#                 val_loss += single_loss.item() * seq.size(0)\n",
    "# \n",
    "#         val_loss /= len(val_loader.dataset)\n",
    "#         val_losses.append(val_loss)\n",
    "# \n",
    "#         print(f'Epoch {epoch} train loss: {train_loss}, val loss: {val_loss}')\n",
    "# \n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "#             counter = 0\n",
    "#             torch.save(model.state_dict(), 'best_model.pth')\n",
    "#         else:\n",
    "#             counter += 1\n",
    "# \n",
    "#         if counter >= patience:\n",
    "#             print('Early stopping')\n",
    "#             break\n",
    "#     return train_losses, val_losses\n",
    "# \n",
    "# \n",
    "# train_losses, val_losses = train_model(model, train_loader, val_loader, loss_function, optimizer, epochs=200,\n",
    "#                                        patience=10)\n",
    "# \n",
    "# model.load_state_dict(torch.load('best_model.pth'))\n",
    "# \n",
    "# model.eval()\n",
    "# test_predictions = []\n",
    "# \n",
    "# with torch.no_grad():\n",
    "#     for seq, labels in test_loader:\n",
    "#         seq, labels = seq.to(device), labels.to(device)\n",
    "#         y_pred = model(seq)\n",
    "#         test_predictions.append(y_pred.cpu().numpy())\n",
    "# \n",
    "# test_predictions = np.concatenate(test_predictions, axis=0)\n",
    "# test_predictions = scaler.inverse_transform(test_predictions.reshape(-1, 1))\n",
    "# y_test = scaler.inverse_transform(y_test.cpu().numpy().reshape(-1, 1))\n",
    "# \n",
    "# mae = np.mean(np.abs(test_predictions - y_test))\n",
    "# mse = np.mean((test_predictions - y_test) ** 2)\n",
    "# mape = np.mean(np.abs(test_predictions - y_test) / np.abs(y_test)) * 100\n",
    "# rmse = np.sqrt(mse)\n",
    "# print(\"\\n\\n\")\n",
    "# print(\"Metrics:\")\n",
    "# print(f'Mean Squared Error: {mse}')\n",
    "# print(f'Root Mean Squared Error: {rmse}')\n",
    "# print(f'Mean Absolute Error: {mae}')\n",
    "# print(f'Mean Absolute Percentage Error: {mape}')\n",
    "# \n",
    "# # Plotagem das perdas de treinamento e validação\n",
    "# plt.plot(train_losses, label='Training Loss')\n",
    "# plt.plot(val_losses, label='Validation Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ],
   "id": "cd670cddfc773300",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T06:06:31.107351Z",
     "start_time": "2024-07-14T03:56:32.837573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Categorical, Real\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_size = X_train.shape[2]  # Supondo que X_train seja um tensor com a forma (n_samples, seq_len, n_features)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Definição do modelo LSTM\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, num_layers, output_size, drop_prob, activation_function):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, _ = self.lstm(input_seq)\n",
    "        predictions = self.linear(lstm_out[:, -1, :])\n",
    "        if self.activation_function == 'relu':\n",
    "            predictions = nn.ReLU()(predictions)\n",
    "        elif self.activation_function == 'sigmoid':\n",
    "            predictions = nn.Sigmoid()(predictions)\n",
    "        return predictions\n",
    "\n",
    "def train_and_evaluate_lstm(input_size, hidden_layer_size, num_layers, lr, batch_size, drop_prob, activation_function, \n",
    "                            weight_decay, num_epochs, patience):\n",
    "    model = LSTM(\n",
    "        input_size=input_size,\n",
    "        hidden_layer_size=hidden_layer_size,\n",
    "        num_layers=num_layers,\n",
    "        drop_prob=drop_prob,\n",
    "        output_size=1,\n",
    "        activation_function=activation_function\n",
    "    ).to(device)\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    train_data = TensorDataset(X_train, y_train)\n",
    "    val_data = TensorDataset(X_val, y_val)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Early stopping \n",
    "    best_val_loss = np.inf\n",
    "    epochs_no_improve = 0\n",
    "    val_losses = []\n",
    "\n",
    "    def train_model():\n",
    "        model.train()\n",
    "        for seq, labels in train_loader:\n",
    "            seq, labels = seq.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(seq)\n",
    "            single_loss = loss_function(y_pred, labels)\n",
    "            single_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    def evaluate_model():\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for seq, labels in val_loader:\n",
    "                seq, labels = seq.to(device), labels.to(device)\n",
    "                y_pred = model(seq)\n",
    "                single_loss = loss_function(y_pred, labels)\n",
    "                val_loss += single_loss.item() * seq.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        return val_loss\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_model()\n",
    "        val_loss = evaluate_model()\n",
    "        val_losses.append(val_loss)\n",
    "        # print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {val_loss}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), \"best_model_lstm_{:.4f}.pth\".format(val_loss))\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                print(\"Early stopping after {} epochs\".format(epoch + 1))\n",
    "                break\n",
    "\n",
    "    return model, val_losses\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class PyTorchLSTMRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, hidden_layer_size=100, num_layers=2, lr=0.001, batch_size=64, drop_prob=0.2,\n",
    "                 activation_function='relu', weight_decay=1e-8, num_epochs=50, patience=10):\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lr = lr\n",
    "        self.drop_prob = drop_prob\n",
    "        self.batch_size = batch_size\n",
    "        self.activation_function = activation_function\n",
    "        self.weight_decay = weight_decay\n",
    "        self.num_epochs = num_epochs\n",
    "        self.patience = patience\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model, self.val_losses = train_and_evaluate_lstm(\n",
    "            input_size=input_size,\n",
    "            hidden_layer_size=self.hidden_layer_size,\n",
    "            num_layers=self.num_layers,\n",
    "            lr=self.lr,\n",
    "            batch_size=self.batch_size,\n",
    "            drop_prob=self.drop_prob,\n",
    "            activation_function=self.activation_function,\n",
    "            weight_decay=self.weight_decay,\n",
    "            num_epochs=self.num_epochs,\n",
    "            patience=self.patience\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        test_data = torch.from_numpy(X).float()\n",
    "        test_loader = DataLoader(test_data, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for seq in test_loader:\n",
    "                seq = seq.to(device)\n",
    "                y_pred = self.model(seq)\n",
    "                predictions.append(y_pred.cpu().numpy())\n",
    "\n",
    "        predictions = np.concatenate(predictions, axis=0)\n",
    "        return predictions\n",
    "\n",
    "# Parâmetros para busca\n",
    "param_space = {\n",
    "    'hidden_layer_size': Integer(32, 256),\n",
    "    'lr': Real(0.0001, 0.1, prior='log-uniform'),\n",
    "    'num_layers': Integer(1, 5),\n",
    "    'batch_size': Categorical([64, 96, 128]),\n",
    "    'num_epochs':  Categorical([400]),\n",
    "    'activation_function': Categorical(['relu', 'sigmoid', 'tanh']),\n",
    "    'drop_prob': Categorical([0.1, 0.2, 0.3])\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# Usando BayesSearchCV\n",
    "bayes_search = BayesSearchCV(estimator=PyTorchLSTMRegressor(), search_spaces=param_space,\n",
    "                             scoring='neg_mean_squared_error', cv=tscv, n_iter=30, random_state=42, verbose=3)\n",
    "bayes_search.fit(X_train.numpy(), y_train.numpy())\n",
    "\n",
    "print(\"Best Parameters:\", bayes_search.best_params_)\n",
    "print(\"Best Score:\", -bayes_search.best_score_)\n"
   ],
   "id": "149c4f7e7d058a8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 14 epochs\n",
      "[CV 1/3] END activation_function=sigmoid, batch_size=128, drop_prob=0.3, hidden_layer_size=103, lr=0.010243393225105073, num_epochs=400, num_layers=2;, score=-0.007 total time=  20.2s\n",
      "Early stopping after 47 epochs\n",
      "[CV 2/3] END activation_function=sigmoid, batch_size=128, drop_prob=0.3, hidden_layer_size=103, lr=0.010243393225105073, num_epochs=400, num_layers=2;, score=-0.001 total time= 1.1min\n",
      "Early stopping after 16 epochs\n",
      "[CV 3/3] END activation_function=sigmoid, batch_size=128, drop_prob=0.3, hidden_layer_size=103, lr=0.010243393225105073, num_epochs=400, num_layers=2;, score=-0.003 total time=  22.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 12 epochs\n",
      "[CV 1/3] END activation_function=tanh, batch_size=128, drop_prob=0.1, hidden_layer_size=245, lr=0.03911863988415668, num_epochs=400, num_layers=2;, score=-0.003 total time=  17.5s\n",
      "Early stopping after 11 epochs\n",
      "[CV 2/3] END activation_function=tanh, batch_size=128, drop_prob=0.1, hidden_layer_size=245, lr=0.03911863988415668, num_epochs=400, num_layers=2;, score=-0.005 total time=  16.3s\n",
      "Early stopping after 26 epochs\n",
      "[CV 3/3] END activation_function=tanh, batch_size=128, drop_prob=0.1, hidden_layer_size=245, lr=0.03911863988415668, num_epochs=400, num_layers=2;, score=-0.006 total time=  37.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 78 epochs\n",
      "[CV 1/3] END activation_function=sigmoid, batch_size=128, drop_prob=0.1, hidden_layer_size=129, lr=0.0003663241571989199, num_epochs=400, num_layers=2;, score=-0.001 total time= 1.8min\n",
      "Early stopping after 66 epochs\n",
      "[CV 2/3] END activation_function=sigmoid, batch_size=128, drop_prob=0.1, hidden_layer_size=129, lr=0.0003663241571989199, num_epochs=400, num_layers=2;, score=-0.001 total time= 1.5min\n",
      "Early stopping after 41 epochs\n",
      "[CV 3/3] END activation_function=sigmoid, batch_size=128, drop_prob=0.1, hidden_layer_size=129, lr=0.0003663241571989199, num_epochs=400, num_layers=2;, score=-0.001 total time=  55.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 29 epochs\n",
      "[CV 1/3] END activation_function=tanh, batch_size=64, drop_prob=0.2, hidden_layer_size=212, lr=0.003708147357379244, num_epochs=400, num_layers=4;, score=-0.001 total time= 1.9min\n",
      "Early stopping after 22 epochs\n",
      "[CV 2/3] END activation_function=tanh, batch_size=64, drop_prob=0.2, hidden_layer_size=212, lr=0.003708147357379244, num_epochs=400, num_layers=4;, score=-0.001 total time= 1.4min\n",
      "Early stopping after 58 epochs\n",
      "[CV 3/3] END activation_function=tanh, batch_size=64, drop_prob=0.2, hidden_layer_size=212, lr=0.003708147357379244, num_epochs=400, num_layers=4;, score=-0.001 total time= 3.8min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 11 epochs\n",
      "[CV 1/3] END activation_function=tanh, batch_size=96, drop_prob=0.2, hidden_layer_size=192, lr=0.05147024286785697, num_epochs=400, num_layers=3;, score=-0.009 total time=  38.1s\n",
      "Early stopping after 12 epochs\n",
      "[CV 2/3] END activation_function=tanh, batch_size=96, drop_prob=0.2, hidden_layer_size=192, lr=0.05147024286785697, num_epochs=400, num_layers=3;, score=-0.003 total time=  41.5s\n",
      "Early stopping after 14 epochs\n",
      "[CV 3/3] END activation_function=tanh, batch_size=96, drop_prob=0.2, hidden_layer_size=192, lr=0.05147024286785697, num_epochs=400, num_layers=3;, score=-0.006 total time=  48.2s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 27 epochs\n",
      "[CV 1/3] END activation_function=tanh, batch_size=128, drop_prob=0.1, hidden_layer_size=74, lr=0.025206334448741735, num_epochs=400, num_layers=3;, score=-0.001 total time=  34.6s\n",
      "Early stopping after 40 epochs\n",
      "[CV 2/3] END activation_function=tanh, batch_size=128, drop_prob=0.1, hidden_layer_size=74, lr=0.025206334448741735, num_epochs=400, num_layers=3;, score=-0.001 total time=  51.7s\n",
      "Early stopping after 19 epochs\n",
      "[CV 3/3] END activation_function=tanh, batch_size=128, drop_prob=0.1, hidden_layer_size=74, lr=0.025206334448741735, num_epochs=400, num_layers=3;, score=-0.001 total time=  23.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 17 epochs\n",
      "[CV 1/3] END activation_function=sigmoid, batch_size=128, drop_prob=0.2, hidden_layer_size=228, lr=0.005995964127756074, num_epochs=400, num_layers=4;, score=-0.003 total time=  35.4s\n",
      "Early stopping after 17 epochs\n",
      "[CV 2/3] END activation_function=sigmoid, batch_size=128, drop_prob=0.2, hidden_layer_size=228, lr=0.005995964127756074, num_epochs=400, num_layers=4;, score=-0.003 total time=  35.2s\n",
      "Early stopping after 13 epochs\n",
      "[CV 3/3] END activation_function=sigmoid, batch_size=128, drop_prob=0.2, hidden_layer_size=228, lr=0.005995964127756074, num_epochs=400, num_layers=4;, score=-0.003 total time=  27.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 65 epochs\n",
      "[CV 1/3] END activation_function=sigmoid, batch_size=128, drop_prob=0.2, hidden_layer_size=220, lr=0.0009379505596171679, num_epochs=400, num_layers=3;, score=-0.001 total time= 1.9min\n",
      "Early stopping after 11 epochs\n",
      "[CV 2/3] END activation_function=sigmoid, batch_size=128, drop_prob=0.2, hidden_layer_size=220, lr=0.0009379505596171679, num_epochs=400, num_layers=3;, score=-0.003 total time=  19.1s\n",
      "Early stopping after 43 epochs\n",
      "[CV 3/3] END activation_function=sigmoid, batch_size=128, drop_prob=0.2, hidden_layer_size=220, lr=0.0009379505596171679, num_epochs=400, num_layers=3;, score=-0.001 total time= 1.3min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 34 epochs\n",
      "[CV 1/3] END activation_function=tanh, batch_size=128, drop_prob=0.3, hidden_layer_size=125, lr=0.001390574606467376, num_epochs=400, num_layers=1;, score=-0.001 total time=  33.4s\n",
      "Early stopping after 40 epochs\n",
      "[CV 2/3] END activation_function=tanh, batch_size=128, drop_prob=0.3, hidden_layer_size=125, lr=0.001390574606467376, num_epochs=400, num_layers=1;, score=-0.001 total time=  39.4s\n",
      "Early stopping after 51 epochs\n",
      "[CV 3/3] END activation_function=tanh, batch_size=128, drop_prob=0.3, hidden_layer_size=125, lr=0.001390574606467376, num_epochs=400, num_layers=1;, score=-0.001 total time=  50.0s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 13 epochs\n",
      "[CV 1/3] END activation_function=relu, batch_size=128, drop_prob=0.3, hidden_layer_size=89, lr=0.0054449388745626505, num_epochs=400, num_layers=2;, score=-0.007 total time=  14.7s\n",
      "Early stopping after 12 epochs\n",
      "[CV 2/3] END activation_function=relu, batch_size=128, drop_prob=0.3, hidden_layer_size=89, lr=0.0054449388745626505, num_epochs=400, num_layers=2;, score=-0.007 total time=  14.2s\n",
      "Early stopping after 29 epochs\n",
      "[CV 3/3] END activation_function=relu, batch_size=128, drop_prob=0.3, hidden_layer_size=89, lr=0.0054449388745626505, num_epochs=400, num_layers=2;, score=-0.007 total time=  33.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 14 epochs\n",
      "[CV 1/3] END activation_function=relu, batch_size=96, drop_prob=0.3, hidden_layer_size=114, lr=0.00022166168975570045, num_epochs=400, num_layers=3;, score=-0.007 total time=  22.7s\n",
      "Early stopping after 15 epochs\n",
      "[CV 2/3] END activation_function=relu, batch_size=96, drop_prob=0.3, hidden_layer_size=114, lr=0.00022166168975570045, num_epochs=400, num_layers=3;, score=-0.007 total time=  24.5s\n",
      "Early stopping after 35 epochs\n",
      "[CV 3/3] END activation_function=relu, batch_size=96, drop_prob=0.3, hidden_layer_size=114, lr=0.00022166168975570045, num_epochs=400, num_layers=3;, score=-0.001 total time=  56.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 28 epochs\n",
      "[CV 1/3] END activation_function=tanh, batch_size=64, drop_prob=0.1, hidden_layer_size=98, lr=0.019468488417596453, num_epochs=400, num_layers=3;, score=-0.001 total time= 1.1min\n",
      "Early stopping after 27 epochs\n",
      "[CV 2/3] END activation_function=tanh, batch_size=64, drop_prob=0.1, hidden_layer_size=98, lr=0.019468488417596453, num_epochs=400, num_layers=3;, score=-0.003 total time= 1.0min\n",
      "Early stopping after 32 epochs\n",
      "[CV 3/3] END activation_function=tanh, batch_size=64, drop_prob=0.1, hidden_layer_size=98, lr=0.019468488417596453, num_epochs=400, num_layers=3;, score=-0.003 total time= 1.2min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 20 epochs\n",
      "[CV 1/3] END activation_function=relu, batch_size=96, drop_prob=0.2, hidden_layer_size=167, lr=0.00010147002684112354, num_epochs=400, num_layers=5;, score=-0.007 total time= 1.6min\n",
      "Early stopping after 44 epochs\n",
      "[CV 2/3] END activation_function=relu, batch_size=96, drop_prob=0.2, hidden_layer_size=167, lr=0.00010147002684112354, num_epochs=400, num_layers=5;, score=-0.001 total time= 3.5min\n",
      "Early stopping after 79 epochs\n",
      "[CV 3/3] END activation_function=relu, batch_size=96, drop_prob=0.2, hidden_layer_size=167, lr=0.00010147002684112354, num_epochs=400, num_layers=5;, score=-0.001 total time= 6.2min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 58 epochs\n",
      "[CV 1/3] END activation_function=tanh, batch_size=128, drop_prob=0.3, hidden_layer_size=245, lr=0.00067314451120098, num_epochs=400, num_layers=2;, score=-0.001 total time= 1.4min\n",
      "Early stopping after 24 epochs\n",
      "[CV 2/3] END activation_function=tanh, batch_size=128, drop_prob=0.3, hidden_layer_size=245, lr=0.00067314451120098, num_epochs=400, num_layers=2;, score=-0.001 total time=  34.6s\n",
      "Early stopping after 35 epochs\n",
      "[CV 3/3] END activation_function=tanh, batch_size=128, drop_prob=0.3, hidden_layer_size=245, lr=0.00067314451120098, num_epochs=400, num_layers=2;, score=-0.001 total time=  50.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 43 epochs\n",
      "[CV 1/3] END activation_function=relu, batch_size=64, drop_prob=0.1, hidden_layer_size=146, lr=0.00046871689855307807, num_epochs=400, num_layers=4;, score=-0.001 total time= 2.3min\n",
      "Early stopping after 55 epochs\n",
      "[CV 2/3] END activation_function=relu, batch_size=64, drop_prob=0.1, hidden_layer_size=146, lr=0.00046871689855307807, num_epochs=400, num_layers=4;, score=-0.001 total time= 2.9min\n",
      "Early stopping after 23 epochs\n",
      "[CV 3/3] END activation_function=relu, batch_size=64, drop_prob=0.1, hidden_layer_size=146, lr=0.00046871689855307807, num_epochs=400, num_layers=4;, score=-0.007 total time= 1.2min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 16 epochs\n",
      "[CV 1/3] END activation_function=tanh, batch_size=96, drop_prob=0.3, hidden_layer_size=255, lr=0.09368535484675457, num_epochs=400, num_layers=3;, score=-0.003 total time=  35.5s\n",
      "Early stopping after 15 epochs\n",
      "[CV 2/3] END activation_function=tanh, batch_size=96, drop_prob=0.3, hidden_layer_size=255, lr=0.09368535484675457, num_epochs=400, num_layers=3;, score=-0.003 total time=  32.7s\n",
      "Early stopping after 13 epochs\n",
      "[CV 3/3] END activation_function=tanh, batch_size=96, drop_prob=0.3, hidden_layer_size=255, lr=0.09368535484675457, num_epochs=400, num_layers=3;, score=-0.010 total time=  28.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 72 epochs\n",
      "[CV 1/3] END activation_function=sigmoid, batch_size=96, drop_prob=0.2, hidden_layer_size=34, lr=0.0001010759228454105, num_epochs=400, num_layers=4;, score=-0.001 total time= 2.3min\n",
      "Early stopping after 79 epochs\n",
      "[CV 2/3] END activation_function=sigmoid, batch_size=96, drop_prob=0.2, hidden_layer_size=34, lr=0.0001010759228454105, num_epochs=400, num_layers=4;, score=-0.001 total time= 2.5min\n",
      "Early stopping after 86 epochs\n",
      "[CV 3/3] END activation_function=sigmoid, batch_size=96, drop_prob=0.2, hidden_layer_size=34, lr=0.0001010759228454105, num_epochs=400, num_layers=4;, score=-0.001 total time= 2.7min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 45 epochs\n",
      "[CV 1/3] END activation_function=tanh, batch_size=128, drop_prob=0.1, hidden_layer_size=32, lr=0.0013225548025697865, num_epochs=400, num_layers=4;, score=-0.001 total time= 1.1min\n",
      "Early stopping after 51 epochs\n",
      "[CV 2/3] END activation_function=tanh, batch_size=128, drop_prob=0.1, hidden_layer_size=32, lr=0.0013225548025697865, num_epochs=400, num_layers=4;, score=-0.001 total time= 1.2min\n",
      "Early stopping after 54 epochs\n",
      "[CV 3/3] END activation_function=tanh, batch_size=128, drop_prob=0.1, hidden_layer_size=32, lr=0.0013225548025697865, num_epochs=400, num_layers=4;, score=-0.001 total time= 1.3min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 122 epochs\n",
      "[CV 1/3] END activation_function=tanh, batch_size=64, drop_prob=0.2, hidden_layer_size=195, lr=0.0001, num_epochs=400, num_layers=1;, score=-0.001 total time= 4.2min\n",
      "Early stopping after 112 epochs\n",
      "[CV 2/3] END activation_function=tanh, batch_size=64, drop_prob=0.2, hidden_layer_size=195, lr=0.0001, num_epochs=400, num_layers=1;, score=-0.001 total time= 3.9min\n",
      "Early stopping after 131 epochs\n",
      "[CV 3/3] END activation_function=tanh, batch_size=64, drop_prob=0.2, hidden_layer_size=195, lr=0.0001, num_epochs=400, num_layers=1;, score=-0.001 total time= 4.6min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 53 epochs\n",
      "[CV 1/3] END activation_function=sigmoid, batch_size=64, drop_prob=0.3, hidden_layer_size=240, lr=0.00010894063509124496, num_epochs=400, num_layers=3;, score=-0.001 total time= 2.9min\n",
      "Early stopping after 78 epochs\n",
      "[CV 2/3] END activation_function=sigmoid, batch_size=64, drop_prob=0.3, hidden_layer_size=240, lr=0.00010894063509124496, num_epochs=400, num_layers=3;, score=-0.001 total time= 4.3min\n",
      "Early stopping after 35 epochs\n",
      "[CV 3/3] END activation_function=sigmoid, batch_size=64, drop_prob=0.3, hidden_layer_size=240, lr=0.00010894063509124496, num_epochs=400, num_layers=3;, score=-0.001 total time= 1.9min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 19 epochs\n",
      "[CV 1/3] END activation_function=relu, batch_size=64, drop_prob=0.1, hidden_layer_size=252, lr=0.07758934960208479, num_epochs=400, num_layers=2;, score=-0.007 total time=  51.8s\n",
      "Early stopping after 22 epochs\n",
      "[CV 2/3] END activation_function=relu, batch_size=64, drop_prob=0.1, hidden_layer_size=252, lr=0.07758934960208479, num_epochs=400, num_layers=2;, score=-0.007 total time=  58.8s\n",
      "Early stopping after 15 epochs\n",
      "[CV 3/3] END activation_function=relu, batch_size=64, drop_prob=0.1, hidden_layer_size=252, lr=0.07758934960208479, num_epochs=400, num_layers=2;, score=-0.007 total time=  40.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 114 epochs\n",
      "[CV 1/3] END activation_function=tanh, batch_size=96, drop_prob=0.3, hidden_layer_size=32, lr=0.00010055010637040224, num_epochs=400, num_layers=4;, score=-0.001 total time= 3.5min\n",
      "Early stopping after 110 epochs\n",
      "[CV 2/3] END activation_function=tanh, batch_size=96, drop_prob=0.3, hidden_layer_size=32, lr=0.00010055010637040224, num_epochs=400, num_layers=4;, score=-0.001 total time= 3.4min\n",
      "Early stopping after 59 epochs\n",
      "[CV 3/3] END activation_function=tanh, batch_size=96, drop_prob=0.3, hidden_layer_size=32, lr=0.00010055010637040224, num_epochs=400, num_layers=4;, score=-0.001 total time= 1.8min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 111 epochs\n",
      "[CV 1/3] END activation_function=relu, batch_size=128, drop_prob=0.1, hidden_layer_size=255, lr=0.0001520661487725003, num_epochs=400, num_layers=1;, score=-0.001 total time= 2.2min\n",
      "Early stopping after 111 epochs\n",
      "[CV 2/3] END activation_function=relu, batch_size=128, drop_prob=0.1, hidden_layer_size=255, lr=0.0001520661487725003, num_epochs=400, num_layers=1;, score=-0.001 total time= 2.2min\n",
      "Early stopping after 44 epochs\n",
      "[CV 3/3] END activation_function=relu, batch_size=128, drop_prob=0.1, hidden_layer_size=255, lr=0.0001520661487725003, num_epochs=400, num_layers=1;, score=-0.001 total time=  52.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 30 epochs\n",
      "[CV 1/3] END activation_function=tanh, batch_size=64, drop_prob=0.3, hidden_layer_size=32, lr=0.000488354637710062, num_epochs=400, num_layers=3;, score=-0.001 total time= 1.2min\n",
      "Early stopping after 28 epochs\n",
      "[CV 2/3] END activation_function=tanh, batch_size=64, drop_prob=0.3, hidden_layer_size=32, lr=0.000488354637710062, num_epochs=400, num_layers=3;, score=-0.001 total time= 1.1min\n",
      "Early stopping after 50 epochs\n",
      "[CV 3/3] END activation_function=tanh, batch_size=64, drop_prob=0.3, hidden_layer_size=32, lr=0.000488354637710062, num_epochs=400, num_layers=3;, score=-0.001 total time= 2.0min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 15 epochs\n",
      "[CV 1/3] END activation_function=relu, batch_size=64, drop_prob=0.2, hidden_layer_size=33, lr=0.09842486636999824, num_epochs=400, num_layers=1;, score=-0.007 total time=  31.7s\n",
      "Early stopping after 14 epochs\n",
      "[CV 2/3] END activation_function=relu, batch_size=64, drop_prob=0.2, hidden_layer_size=33, lr=0.09842486636999824, num_epochs=400, num_layers=1;, score=-0.007 total time=  29.4s\n",
      "Early stopping after 13 epochs\n",
      "[CV 3/3] END activation_function=relu, batch_size=64, drop_prob=0.2, hidden_layer_size=33, lr=0.09842486636999824, num_epochs=400, num_layers=1;, score=-0.007 total time=  27.2s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 35 epochs\n",
      "[CV 1/3] END activation_function=tanh, batch_size=96, drop_prob=0.1, hidden_layer_size=256, lr=0.0001, num_epochs=400, num_layers=5;, score=-0.001 total time= 1.7min\n",
      "Early stopping after 45 epochs\n",
      "[CV 2/3] END activation_function=tanh, batch_size=96, drop_prob=0.1, hidden_layer_size=256, lr=0.0001, num_epochs=400, num_layers=5;, score=-0.001 total time= 2.2min\n",
      "Early stopping after 28 epochs\n",
      "[CV 3/3] END activation_function=tanh, batch_size=96, drop_prob=0.1, hidden_layer_size=256, lr=0.0001, num_epochs=400, num_layers=5;, score=-0.001 total time= 1.4min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 50 epochs\n",
      "[CV 1/3] END activation_function=tanh, batch_size=128, drop_prob=0.2, hidden_layer_size=129, lr=0.0001, num_epochs=400, num_layers=5;, score=-0.001 total time= 2.3min\n",
      "Early stopping after 50 epochs\n",
      "[CV 2/3] END activation_function=tanh, batch_size=128, drop_prob=0.2, hidden_layer_size=129, lr=0.0001, num_epochs=400, num_layers=5;, score=-0.001 total time= 2.3min\n",
      "Early stopping after 45 epochs\n",
      "[CV 3/3] END activation_function=tanh, batch_size=128, drop_prob=0.2, hidden_layer_size=129, lr=0.0001, num_epochs=400, num_layers=5;, score=-0.001 total time= 2.1min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 24 epochs\n",
      "[CV 1/3] END activation_function=relu, batch_size=96, drop_prob=0.1, hidden_layer_size=74, lr=0.0012401605576382992, num_epochs=400, num_layers=3;, score=-0.007 total time=  39.9s\n",
      "Early stopping after 36 epochs\n",
      "[CV 2/3] END activation_function=relu, batch_size=96, drop_prob=0.1, hidden_layer_size=74, lr=0.0012401605576382992, num_epochs=400, num_layers=3;, score=-0.001 total time=  59.6s\n",
      "Early stopping after 46 epochs\n",
      "[CV 3/3] END activation_function=relu, batch_size=96, drop_prob=0.1, hidden_layer_size=74, lr=0.0012401605576382992, num_epochs=400, num_layers=3;, score=-0.001 total time= 1.3min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 14 epochs\n",
      "[CV 1/3] END activation_function=relu, batch_size=128, drop_prob=0.1, hidden_layer_size=128, lr=0.022247440503491683, num_epochs=400, num_layers=4;, score=-0.007 total time=  19.9s\n",
      "Early stopping after 23 epochs\n",
      "[CV 2/3] END activation_function=relu, batch_size=128, drop_prob=0.1, hidden_layer_size=128, lr=0.022247440503491683, num_epochs=400, num_layers=4;, score=-0.007 total time=  32.4s\n",
      "Early stopping after 12 epochs\n",
      "[CV 3/3] END activation_function=relu, batch_size=128, drop_prob=0.1, hidden_layer_size=128, lr=0.022247440503491683, num_epochs=400, num_layers=4;, score=-0.007 total time=  17.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Early stopping after 11 epochs\n",
      "[CV 1/3] END activation_function=relu, batch_size=96, drop_prob=0.3, hidden_layer_size=232, lr=0.09922840403847222, num_epochs=400, num_layers=4;, score=-0.007 total time=  28.4s\n",
      "Early stopping after 41 epochs\n",
      "[CV 2/3] END activation_function=relu, batch_size=96, drop_prob=0.3, hidden_layer_size=232, lr=0.09922840403847222, num_epochs=400, num_layers=4;, score=-0.007 total time= 1.8min\n",
      "Early stopping after 24 epochs\n",
      "[CV 3/3] END activation_function=relu, batch_size=96, drop_prob=0.3, hidden_layer_size=232, lr=0.09922840403847222, num_epochs=400, num_layers=4;, score=-0.007 total time= 1.0min\n",
      "Early stopping after 39 epochs\n",
      "Best Parameters: OrderedDict([('activation_function', 'tanh'), ('batch_size', 128), ('drop_prob', 0.1), ('hidden_layer_size', 32), ('lr', 0.0013225548025697865), ('num_epochs', 400), ('num_layers', 4)])\n",
      "Best Score: 0.0012780505154902737\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T03:55:46.114400Z",
     "start_time": "2024-07-14T03:55:46.114400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Treinar o modelo com os melhores parâmetros encontrados\n",
    "best_params = bayes_search.best_params_\n",
    "model, val_losses = train_and_evaluate_lstm(input_size=input_size, **best_params, lr=0.001, weight_decay=1e-8, patience=5)\n",
    "\n",
    "# Fazer predições\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_val.to(device)).cpu().numpy()"
   ],
   "id": "b8a31fb7966ffc50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "plt.plot(y_val.numpy(), label='Valores Reais', color='black', alpha=1)\n",
    "plt.plot(y_pred, label='Valores de Previsão', color='green', alpha=0.5)\n",
    "plt.xlabel('Amostras')\n",
    "plt.ylabel('Valores')\n",
    "plt.title('Valores Reais vs. Valores de Previsão')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "34d7212f6cc921b5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
