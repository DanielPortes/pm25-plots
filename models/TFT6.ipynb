{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Modelo Transformer com Otimização de Hiperparâmetros\n",
    "funcionando com PyTorch e Optuna"
   ],
   "id": "70270859dba0d6fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:55:53.461708Z",
     "start_time": "2024-08-27T15:55:49.463497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import optuna\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from copy import deepcopy as dc\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import optuna\n",
    "import math\n",
    "\n",
    "data_hoje = datetime.now().strftime('%d-%m')\n",
    "inicio_execucao = pd.Timestamp.now()\n",
    "\n",
    "os.makedirs(f'../logs/{data_hoje}', exist_ok=True)\n",
    "os.makedirs(f'../plots/{data_hoje}', exist_ok=True)\n",
    "os.makedirs(f'../best_models/{data_hoje}', exist_ok=True)\n",
    "\n",
    "logging.basicConfig(filename=f'../logs/{data_hoje}/transformer_optuna.log', level=logging.INFO, format='- %(message)s')\n",
    "logging.info('-' * 50)\n",
    "logging.info(f'{inicio_execucao} - Iniciando o processo de otimização e treinamento do modelo BiLSTM')\n",
    "\n",
    "df_original = pd.read_csv('../dados_tratados/combinado/Piratininga/Piratininga_tratado_combinado.csv',\n",
    "                          usecols=['PM2.5', 'Data e Hora', 'PM10', 'Monóxido de Carbono'], low_memory=False)\n",
    "\n",
    "df_original['Data e Hora'] = pd.to_datetime(df_original['Data e Hora'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_original.index = df_original['Data e Hora']\n",
    "df_original.sort_index(inplace=True)\n",
    "\n",
    "colunas_selecionadas = ['PM2.5', 'PM10', 'Monóxido de Carbono']\n",
    "logging.info(f\"Colunas selecionadas: {colunas_selecionadas}\")\n",
    "\n",
    "df = df_original[colunas_selecionadas]\n",
    "df = df.loc['2019-01-01':'2022-01-01']\n",
    "\n",
    "logging.info(f\"Período de análise: 2019-01-01 a 2022-01-01\")\n",
    "df = df.apply(pd.to_numeric, errors='coerce')"
   ],
   "id": "6e68fea9a740698b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:56:00.591782Z",
     "start_time": "2024-08-27T15:55:53.472713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def log_imputation(method_name, impute_function, df):\n",
    "    df_imputed = impute_function(df)\n",
    "    logging.info(f\"Imputação realizada usando: {method_name}\")\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def Mice_imputer(df):\n",
    "    mice_imputer = IterativeImputer(\n",
    "        estimator=ExtraTreesRegressor(n_estimators=100, random_state=42),\n",
    "        max_iter=10,\n",
    "        random_state=42,\n",
    "        n_nearest_features=None,\n",
    "        initial_strategy='mean'\n",
    "    )\n",
    "\n",
    "    df_imputed = pd.DataFrame(\n",
    "        mice_imputer.fit_transform(df),\n",
    "        columns=df.columns,\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def mean_imputer(df):\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    df_imputed = pd.DataFrame(\n",
    "        imputer.fit_transform(df),\n",
    "        columns=df.columns,\n",
    "        index=df.index\n",
    "    )\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def median_imputer(df):\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    df_imputed = pd.DataFrame(\n",
    "        imputer.fit_transform(df),\n",
    "        columns=df.columns,\n",
    "        index=df.index\n",
    "    )\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def forward_fill_imputer(df):\n",
    "    df_imputed = df.fillna(method='ffill')\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def backward_fill_imputer(df):\n",
    "    df_imputed = df.fillna(method='bfill')\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def linear_interpolation_imputer(df):\n",
    "    df_imputed = df.interpolate(method='linear')\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def exponential_smoothing_imputer(df):\n",
    "    df_imputed = df.ewm(alpha=0.5).mean()\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def knn_imputer(df):\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    df_imputed = pd.DataFrame(\n",
    "        imputer.fit_transform(df),\n",
    "        columns=df.columns,\n",
    "        index=df.index\n",
    "    )\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "# df_imputed = log_imputation('Mean', mean_imputer, df)\n",
    "# df_imputed = log_imputation('Median', median_imputer, df)\n",
    "# df_imputed = log_imputation('Forward Fill', forward_fill_imputer, df)\n",
    "# df_imputed = log_imputation('Backward Fill', backward_fill_imputer, df)\n",
    "# df_imputed = log_imputation('Linear Interpolation', linear_interpolation_imputer, df)\n",
    "# df_imputed = log_imputation('Exponential Smoothing', exponential_smoothing_imputer, df)\n",
    "df_imputed = log_imputation('KNN', knn_imputer, df)\n",
    "# df_imputed = log_imputation('MICE', Mice_imputer, df)\n"
   ],
   "id": "653a60c672216ebb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-27T15:56:00.932615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_cyclical_features(df):\n",
    "    df['hour'] = df.index.hour\n",
    "    df['day'] = df.index.day\n",
    "    df['month'] = df.index.month\n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day'] / 31)\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day'] / 31)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "\n",
    "    df.drop(['hour', 'day', 'month', 'day_of_week'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_imputed = add_cyclical_features(df_imputed)\n",
    "\n",
    "logging.info(f\"Adicionadas features cíclicas\")\n",
    "\n",
    "\n",
    "def prepare_dataframe_for_lstm(df, n_steps):\n",
    "    df = dc(df)\n",
    "    for col in df.columns:\n",
    "        for i in range(1, n_steps + 1):\n",
    "            df[f'{col}(t-{i})'] = df[col].shift(i)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "lookback = 8\n",
    "shifted_df = prepare_dataframe_for_lstm(df_imputed, lookback)\n",
    "\n",
    "# **Correção do possível vazamento de dados**\n",
    "# Normalizar apenas os dados de treino e aplicar a transformação para validação e teste\n",
    "train_split = int(len(shifted_df) * 0.7)\n",
    "val_split = int(len(shifted_df) * 0.85)\n",
    "\n",
    "train_df = shifted_df[:train_split]\n",
    "val_df = shifted_df[train_split:val_split]\n",
    "test_df = shifted_df[val_split:]\n",
    "\n",
    "preprocessing_scaler = StandardScaler()\n",
    "preprocessing_scaler.fit(train_df)\n",
    "\n",
    "X_train = preprocessing_scaler.transform(train_df)[:, len(colunas_selecionadas):]\n",
    "y_train = preprocessing_scaler.transform(train_df)[:, 0]\n",
    "\n",
    "X_val = preprocessing_scaler.transform(val_df)[:, len(colunas_selecionadas):]\n",
    "y_val = preprocessing_scaler.transform(val_df)[:, 0]\n",
    "\n",
    "X_test = preprocessing_scaler.transform(test_df)[:, len(colunas_selecionadas):]\n",
    "y_test = preprocessing_scaler.transform(test_df)[:, 0]\n",
    "\n",
    "X_train = dc(np.flip(X_train, axis=1))\n",
    "X_val = dc(np.flip(X_val, axis=1))\n",
    "X_test = dc(np.flip(X_test, axis=1))\n",
    "\n",
    "X_train = X_train.reshape((-1, lookback, X_train.shape[1] // lookback))\n",
    "X_val = X_val.reshape((-1, lookback, X_val.shape[1] // lookback))\n",
    "X_test = X_test.reshape((-1, lookback, X_test.shape[1] // lookback))\n",
    "y_train = y_train.reshape((-1, 1))\n",
    "y_val = y_val.reshape((-1, 1))\n",
    "y_test = y_test.reshape((-1, 1))\n",
    "\n",
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train).float()\n",
    "X_val = torch.tensor(X_val).float()\n",
    "y_val = torch.tensor(y_val).float()\n",
    "X_test = torch.tensor(X_test).float()\n",
    "y_test = torch.tensor(y_test).float()\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, input_size, d_model, nhead, num_layers, dropout):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        self.encoder = nn.Linear(input_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=d_model * 4, dropout=dropout,\n",
    "                                                    batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.decoder = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.encoder(src)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.decoder(output[:, -1, :])\n",
    "        return output\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    d_model = trial.suggest_int('d_model', 128, 512, step=64)\n",
    "    nhead_options = [i for i in range(2, 9) if d_model % i == 0]\n",
    "    nhead = trial.suggest_categorical('nhead', nhead_options)\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 4)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "\n",
    "    model = TimeSeriesTransformer(input_size=X_train.shape[2], d_model=d_model,\n",
    "                                  nhead=nhead, num_layers=num_layers, dropout=dropout).to(device)\n",
    "\n",
    "    criterion = nn.HuberLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    train_loader = DataLoader(TimeSeriesDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TimeSeriesDataset(X_val, y_val), batch_size=batch_size)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_X)\n",
    "                val_loss += criterion(outputs, batch_y).item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        trial.report(val_loss, epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=3)\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print('Value: ', trial.value)\n",
    "print('Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')\n",
    "\n",
    "best_params = study.best_params\n",
    "final_model = TimeSeriesTransformer(input_size=X_train.shape[2], d_model=best_params['d_model'],\n",
    "                                    nhead=best_params['nhead'], num_layers=best_params['num_layers'],\n",
    "                                    dropout=best_params['dropout']).to(device)\n",
    "\n",
    "criterion = nn.HuberLoss()\n",
    "optimizer = optim.AdamW(final_model.parameters(), lr=best_params['learning_rate'],\n",
    "                        weight_decay=best_params['weight_decay'])\n",
    "\n",
    "scaler = GradScaler()\n",
    "num_workers = 0\n",
    "\n",
    "train_loader = DataLoader(TimeSeriesDataset(X_train, y_train), batch_size=best_params['batch_size'], shuffle=True,\n",
    "                          num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(TimeSeriesDataset(X_val, y_val), batch_size=best_params['batch_size'], num_workers=num_workers,\n",
    "                        pin_memory=True)\n",
    "\n",
    "num_epochs = 500\n",
    "best_val_loss = float('inf')\n",
    "patience = 50\n",
    "no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    final_model.train()\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = final_model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(final_model.parameters(), max_norm=1.0)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "    final_model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            with autocast():\n",
    "                outputs = final_model(batch_X)\n",
    "                val_loss += criterion(outputs, batch_y).item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improve = 0\n",
    "        torch.save(final_model.state_dict(), f'../best_models/{data_hoje}/best_model.pth')\n",
    "    else:\n",
    "        no_improve += 1\n",
    "\n",
    "    if no_improve >= patience:\n",
    "        print(f'Early stopping triggered after {epoch + 1} epochs')\n",
    "        break"
   ],
   "id": "935842759ebff03b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 12:56:01,081] A new study created in memory with name: no-name-d3670a8e-76c8-44df-be47-06aeba95f16e\n",
      "[W 2024-08-27 14:56:38,644] Trial 0 failed with parameters: {'d_model': 512, 'nhead': 8, 'num_layers': 3, 'dropout': 0.41434816404503005, 'learning_rate': 1.1740371552232116e-05, 'batch_size': 64, 'weight_decay': 1.078638600540336e-05} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\portes\\AppData\\Local\\Temp\\ipykernel_19896\\1937862449.py\", line 149, in objective\n",
      "    loss.backward()\n",
      "  File \"C:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"C:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"C:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py\", line 768, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-08-27 14:56:38,693] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 171\u001B[0m\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m val_loss\n\u001B[0;32m    170\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mminimize\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 171\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    173\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBest trial:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    174\u001B[0m trial \u001B[38;5;241m=\u001B[39m study\u001B[38;5;241m.\u001B[39mbest_trial\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\optuna\\study\\study.py:451\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    348\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[0;32m    349\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    350\u001B[0m     func: ObjectiveFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    357\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    358\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    359\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[0;32m    360\u001B[0m \n\u001B[0;32m    361\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    449\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[0;32m    450\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 451\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    453\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    454\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    455\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    456\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    458\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    459\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    461\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001B[0m, in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 62\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     63\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     64\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     75\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    156\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 159\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    161\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[0;32m    162\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[0;32m    164\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    240\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    242\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    243\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[0;32m    244\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[0;32m    246\u001B[0m ):\n\u001B[1;32m--> 247\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[0;32m    248\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[0;32m    195\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 196\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    198\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[0;32m    199\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[1;32mIn[3], line 149\u001B[0m, in \u001B[0;36mobjective\u001B[1;34m(trial)\u001B[0m\n\u001B[0;32m    147\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m model(batch_X)\n\u001B[0;32m    148\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs, batch_y)\n\u001B[1;32m--> 149\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    150\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    152\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\_tensor.py:521\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    512\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    513\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    514\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    519\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    520\u001B[0m     )\n\u001B[1;32m--> 521\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    284\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    286\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 289\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    290\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    291\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    292\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    293\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    294\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    295\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    296\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    297\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py:768\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    766\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    767\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 768\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    769\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    770\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    771\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    772\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Carregar o modelo final\n",
    "final_model.load_state_dict(torch.load(f'../best_models/{data_hoje}/best_model.pth'))\n",
    "\n",
    "# Criar o DataLoader para os dados de teste\n",
    "test_loader = DataLoader(TimeSeriesDataset(X_test, y_test), batch_size=best_params['batch_size'])\n",
    "final_model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        outputs = final_model(batch_X)\n",
    "        test_loss += criterion(outputs, batch_y).item()\n",
    "        predictions.extend(outputs.cpu().numpy().squeeze())\n",
    "        actuals.extend(batch_y.cpu().numpy().squeeze())\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# Desnormalização\n",
    "def inverse_transform_data(data, preprocessing_scaler):\n",
    "    if data.ndim == 1:\n",
    "        data = data.reshape(-1, 1)\n",
    "    # Criar dummy array para desnormalizar com a mesma escala usada anteriormente\n",
    "    dummies = np.zeros((data.shape[0], preprocessing_scaler.n_features_in_))\n",
    "    dummies[:, 0] = data.ravel()  # Use ravel() para garantir que o array seja 1D\n",
    "    dummies = preprocessing_scaler.inverse_transform(dummies)\n",
    "    return dummies[:, 0]\n",
    "\n",
    "# Aplicar a desnormalização\n",
    "predictions = inverse_transform_data(np.array(predictions), preprocessing_scaler)\n",
    "actuals = inverse_transform_data(np.array(actuals), preprocessing_scaler)\n",
    "\n",
    "# Continuar com o cálculo das métricas e a visualização dos resultados\n",
    "mse = mean_squared_error(actuals, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(actuals, predictions)\n",
    "r2 = r2_score(actuals, predictions)\n",
    "mape = np.mean(np.abs((actuals - predictions) / actuals)) * 100\n",
    "\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.4f}')\n",
    "print(f'Mean Absolute Error: {mae:.4f}')\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Absolute Percentage Error: {mape:.4f}')\n",
    "\n",
    "logging.info(f'Mean Squared Error: {mse:.4f}')\n",
    "logging.info(f'Root Mean Squared Error: {rmse:.4f}')\n",
    "logging.info(f'Mean Absolute Error: {mae:.4f}')\n",
    "logging.info(f'R-squared: {r2:.4f}')\n",
    "logging.info(f'Mean Absolute Percentage Error: {mape:.4f}')\n",
    "\n",
    "# Plotar os resultados\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(actuals, label='Actual')\n",
    "plt.plot(predictions, label='Predicted')\n",
    "plt.title('Actual vs Predicted PM2.5 Values')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('PM2.5')\n",
    "plt.legend()\n",
    "plt.savefig(f'../plots/{data_hoje}/actual_vs_predicted.png')\n",
    "plt.close()\n",
    "\n",
    "# Plotar scatter plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(actuals, predictions, alpha=0.5)\n",
    "plt.plot([min(actuals), max(actuals)], [min(actuals), max(actuals)], 'r--', lw=2)\n",
    "plt.xlabel('Actual PM2.5')\n",
    "plt.ylabel('Predicted PM2.5')\n",
    "plt.title('Actual vs Predicted PM2.5 Scatter Plot')\n",
    "plt.savefig(f'../plots/{data_hoje}/scatter_plot.png')\n",
    "plt.close()\n",
    "\n",
    "# Salvar resultados\n",
    "results = pd.DataFrame({'Actual': actuals, 'Predicted': predictions})\n",
    "results.to_csv(f'../results/{data_hoje}/predictions.csv', index=False)\n",
    "\n",
    "# Salvar métricas\n",
    "with open(f'../results/{data_hoje}/metrics.txt', 'w') as f:\n",
    "    f.write(f'Mean Squared Error: {mse:.4f}\\n')\n",
    "    f.write(f'Root Mean Squared Error: {rmse:.4f}\\n')\n",
    "    f.write(f'Mean Absolute Error: {mae:.4f}\\n')\n",
    "    f.write(f'R-squared: {r2:.4f}\\n')\n",
    "\n",
    "print(\"Análise concluída. Resultados salvos nos diretórios correspondentes.\")\n"
   ],
   "id": "af9b2eb5acfc1c4e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
