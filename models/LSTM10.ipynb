{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Modelo LSTM\n",
    "3 colunas\n",
    "pytorch light\n",
    "optuna"
   ],
   "id": "3d3a70a7a3d2c88a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T20:13:17.529437Z",
     "start_time": "2024-08-21T20:13:11.934610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "id": "d14921d7ecd62577",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T20:13:17.544187Z",
     "start_time": "2024-08-21T20:13:17.539966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cria pasta de logs com data de hoje\n",
    "\n",
    "data_hoje = datetime.now().strftime('%d-%m')\n",
    "os.makedirs(f'../logs/{data_hoje}', exist_ok=True)\n",
    "os.makedirs(f'../plots/{data_hoje}', exist_ok=True)"
   ],
   "id": "d8b9a719f4528b69",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T20:13:17.554551Z",
     "start_time": "2024-08-21T20:13:17.549714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "\n",
    "inicio_execucao = pd.Timestamp.now()\n",
    "\n",
    "logging.basicConfig(filename=f'../logs/{data_hoje}/lstm.log', level=logging.INFO, format='- %(message)s')\n",
    "logging.info('-' * 50)\n",
    "logging.info(f'{inicio_execucao} - Iniciando o processo de treinamento do modelo LSTM')"
   ],
   "id": "7f1eda578a581056",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T20:13:17.751100Z",
     "start_time": "2024-08-21T20:13:17.560085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_original = pd.read_csv('../dados_tratados/combinado/Piratininga/Piratininga_tratado_combinado.csv',\n",
    "                          usecols=['PM2.5', 'Data e Hora', 'PM10', 'Monóxido de Carbono'], low_memory=False)"
   ],
   "id": "171955d3a27b508c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T20:13:18.204897Z",
     "start_time": "2024-08-21T20:13:18.107747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_original['Data e Hora'] = pd.to_datetime(df_original['Data e Hora'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_original.index = df_original['Data e Hora']\n",
    "df_original.sort_index(inplace=True)\n",
    "\n",
    "colunas_selecionadas = ['PM2.5', 'PM10', 'Monóxido de Carbono']\n",
    "df = df_original[colunas_selecionadas]\n",
    "\n",
    "df = df.loc['2019-01-01':'2022-01-01']\n",
    "\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "logging.info(f'Colunas Selecionadas: {colunas_selecionadas}')\n",
    "df.head(10)"
   ],
   "id": "d711b48520899f06",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     PM2.5   PM10  Monóxido de Carbono\n",
       "Data e Hora                                           \n",
       "2019-01-01 00:30:00   37.0  45.12                 0.77\n",
       "2019-01-01 01:30:00   23.0  70.53                 0.92\n",
       "2019-01-01 02:30:00   18.0  68.99                 0.81\n",
       "2019-01-01 03:30:00   13.0  59.54                 0.57\n",
       "2019-01-01 04:30:00    7.0  30.84                 0.44\n",
       "2019-01-01 05:30:00    2.0  17.32                 0.43\n",
       "2019-01-01 06:30:00    NaN   8.84                 0.40\n",
       "2019-01-01 07:30:00    NaN  16.81                 0.41\n",
       "2019-01-01 08:30:00    NaN   9.08                 0.41\n",
       "2019-01-01 09:30:00    1.0   6.37                 0.42"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>Monóxido de Carbono</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data e Hora</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:30:00</th>\n",
       "      <td>37.0</td>\n",
       "      <td>45.12</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:30:00</th>\n",
       "      <td>23.0</td>\n",
       "      <td>70.53</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:30:00</th>\n",
       "      <td>18.0</td>\n",
       "      <td>68.99</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:30:00</th>\n",
       "      <td>13.0</td>\n",
       "      <td>59.54</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 04:30:00</th>\n",
       "      <td>7.0</td>\n",
       "      <td>30.84</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 05:30:00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>17.32</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 06:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.84</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 07:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16.81</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 08:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:30:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.37</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T20:13:18.233816Z",
     "start_time": "2024-08-21T20:13:18.224368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def impute_missing_values(df):\n",
    "    return df.interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "\n",
    "df_imputed = impute_missing_values(df)\n",
    "\n",
    "logging.info(f\"Dados ausentes antes da imputação: {df.isna().sum()}\")\n",
    "logging.info(f\"Dados ausentes após a imputação: {df_imputed.isna().sum()}\")"
   ],
   "id": "cf71a13126091c0e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T20:13:19.085117Z",
     "start_time": "2024-08-21T20:13:18.259043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from copy import deepcopy as dc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Preparando os dados para LSTM\n",
    "def prepare_dataframe_for_lstm(df, n_steps):\n",
    "    df = dc(df)\n",
    "    for col in colunas_selecionadas:\n",
    "        for i in range(1, n_steps + 1):\n",
    "            df[f'{col}(t-{i})'] = df[col].shift(i)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "lookback = 8  # 8 horas de lookback\n",
    "shifted_df = prepare_dataframe_for_lstm(df_imputed, lookback)\n",
    "\n",
    "# Normalizando os dados\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "shifted_df_as_np = scaler.fit_transform(shifted_df)\n",
    "\n",
    "X = shifted_df_as_np[:, len(colunas_selecionadas):]\n",
    "y = shifted_df_as_np[:, 0]  # Mantemos PM2.5 como nossa variável alvo\n",
    "\n",
    "X = dc(np.flip(X, axis=1))\n",
    "\n",
    "# Dividindo em conjuntos de treino, validação e teste\n",
    "train_split = int(len(X) * 0.7)\n",
    "val_split = int(len(X) * 0.85)\n",
    "\n",
    "X_train, X_val, X_test = X[:train_split], X[train_split:val_split], X[val_split:]\n",
    "y_train, y_val, y_test = y[:train_split], y[train_split:val_split], y[val_split:]"
   ],
   "id": "d5fef927653f6d40",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T20:13:19.118512Z",
     "start_time": "2024-08-21T20:13:19.115097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TimeSeriesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y).unsqueeze(1)  # Add an extra dimension to match the model output\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ],
   "id": "c0b67d1bc9f8cf14",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T20:13:19.135542Z",
     "start_time": "2024-08-21T20:13:19.129035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTMModel(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, learning_rate):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add a sequence length dimension\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        output = self.fc(lstm_out[:, -1, :])\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.MSELoss()(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.MSELoss()(y_hat, y)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.MSELoss()(y_hat, y)\n",
    "        self.log('test_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
   ],
   "id": "46bb2c33acbea483",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T20:13:19.154144Z",
     "start_time": "2024-08-21T20:13:19.148581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    hidden_size = trial.suggest_int('hidden_size', 32, 256)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "\n",
    "    model = LSTMModel(\n",
    "        input_size=X.shape[1],\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        output_size=1,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "\n",
    "    train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "    val_dataset = TimeSeriesDataset(X_val, y_val)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    early_stop_callback = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
    "    checkpoint_callback = ModelCheckpoint(dirpath=f'../models/{data_hoje}', filename='best_model', save_top_k=1, monitor='val_loss', mode='min')\n",
    "    logger = TensorBoardLogger(f'../logs/{data_hoje}', name='lstm_optuna')\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=100,\n",
    "        callbacks=[early_stop_callback, checkpoint_callback],\n",
    "        logger=logger,\n",
    "        log_every_n_steps=10,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    return trainer.callback_metrics['val_loss'].item()"
   ],
   "id": "e7adff7145697f85",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-08-21T20:13:19.184007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "# Executar a otimização com Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "logging.info(f'Melhor trial: {study.best_trial.params}')\n",
    "\n",
    "# Treinar o modelo final com os melhores hiperparâmetros\n",
    "best_params = study.best_trial.params\n",
    "final_model = LSTMModel(\n",
    "    input_size=X.shape[1],\n",
    "    hidden_size=best_params['hidden_size'],\n",
    "    num_layers=best_params['num_layers'],\n",
    "    output_size=1,\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ],
   "id": "cc68930685ece790",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-21 17:13:19,187] A new study created in memory with name: no-name-900e3611-4cea-4984-b940-bc3e1ca21273\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\dev\\scripts\\pm25-plots\\models\\21-08 exists and is not empty.\n",
      "\n",
      "  | Name | Type   | Params | Mode \n",
      "----------------------------------------\n",
      "0 | lstm | LSTM   | 478 K  | train\n",
      "1 | fc   | Linear | 196    | train\n",
      "----------------------------------------\n",
      "478 K     Trainable params\n",
      "0         Non-trainable params\n",
      "478 K     Total params\n",
      "1.913     Total estimated model params size (MB)\n",
      "2         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e230ef1acd34915be1110ebbbf6ce26"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "C:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0f8866a1394440cb39c787fb75732ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b71527c65eb4bf990c0e8191f47b74a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "979c6b516b7949298bd0459088d61775"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "val_dataset = TimeSeriesDataset(X_val, y_val)\n",
    "test_dataset = TimeSeriesDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=best_params['batch_size'])\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=best_params['batch_size'])\n",
    "\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=f'../models/{data_hoje}', filename='final_model', save_top_k=1, monitor='val_loss', mode='min')\n",
    "logger = TensorBoardLogger(f'../logs/{data_hoje}', name='lstm_final')"
   ],
   "id": "23e74679d14c4e62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=200,\n",
    "    callbacks=[early_stop_callback, checkpoint_callback],\n",
    "    logger=logger,\n",
    "    log_every_n_steps=10,\n",
    ")\n",
    "\n",
    "trainer.fit(final_model, train_loader, val_loader)\n",
    "test_result = trainer.test(final_model, test_loader)\n",
    "\n",
    "logging.info(f'Resultado do teste: {test_result}')\n",
    "\n",
    "# Salvar o modelo final\n",
    "torch.save(final_model.state_dict(), f'../models/{data_hoje}/final_model.pth')\n",
    "\n",
    "fim_execucao = pd.Timestamp.now()\n",
    "logging.info(f'{fim_execucao} - Processo de treinamento do modelo LSTM concluído')\n",
    "logging.info(f'Tempo total de execução: {fim_execucao - inicio_execucao}')"
   ],
   "id": "335a2939826046d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d98bb6b6051a26d9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
