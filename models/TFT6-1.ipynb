{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Modelo CNN-LSTM com Otimização de Hiperparâmetros\n",
    "funcionando com PyTorch e Optuna"
   ],
   "id": "70270859dba0d6fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T00:22:34.997759Z",
     "start_time": "2024-08-24T00:22:34.826682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import logging\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import torch\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "data_hoje = datetime.now().strftime('%d-%m')\n",
    "inicio_execucao = pd.Timestamp.now()\n",
    "\n",
    "os.makedirs(f'../logs/{data_hoje}', exist_ok=True)\n",
    "os.makedirs(f'../plots/{data_hoje}', exist_ok=True)\n",
    "os.makedirs(f'../best_models/{data_hoje}', exist_ok=True)\n",
    "\n",
    "logging.basicConfig(filename=f'../logs/{data_hoje}/bilstm_optuna.log', level=logging.INFO, format='- %(message)s')\n",
    "logging.info('-' * 50)\n",
    "logging.info(f'{inicio_execucao} - Iniciando o processo de otimização e treinamento do modelo BiLSTM')\n",
    "\n",
    "df_original = pd.read_csv('../dados_tratados/combinado/Piratininga/Piratininga_tratado_combinado.csv',\n",
    "                          usecols=['PM2.5', 'Data e Hora', 'PM10', 'Monóxido de Carbono'], low_memory=False)\n",
    "\n",
    "df_original['Data e Hora'] = pd.to_datetime(df_original['Data e Hora'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_original.index = df_original['Data e Hora']\n",
    "df_original.sort_index(inplace=True)\n",
    "\n",
    "colunas_selecionadas = ['PM2.5', 'PM10', 'Monóxido de Carbono']\n",
    "logging.info(f\"Colunas selecionadas: {colunas_selecionadas}\")\n",
    "\n",
    "df = df_original[colunas_selecionadas]\n",
    "df = df.loc['2019-01-01':'2022-01-01']\n",
    "\n",
    "logging.info(f\"Período de análise: 2019-01-01 a 2022-01-01\")\n",
    "df = df.apply(pd.to_numeric, errors='coerce')"
   ],
   "id": "6e68fea9a740698b",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.lib.function_base'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mensemble\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExtraTreesRegressor\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_forecasting\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TemporalFusionTransformer, TimeSeriesDataSet\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_forecasting\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MAE, SMAPE, PoissonLoss, QuantileLoss\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_forecasting\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtemporal_fusion_transformer\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtuning\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m optimize_hyperparameters\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv10\\lib\\site-packages\\pytorch_forecasting\\__init__.py:31\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_forecasting\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      5\u001B[0m     EncoderNormalizer,\n\u001B[0;32m      6\u001B[0m     GroupNormalizer,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      9\u001B[0m     TimeSeriesDataSet,\n\u001B[0;32m     10\u001B[0m )\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_forecasting\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     12\u001B[0m     MAE,\n\u001B[0;32m     13\u001B[0m     MAPE,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     29\u001B[0m     QuantileLoss,\n\u001B[0;32m     30\u001B[0m )\n\u001B[1;32m---> 31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_forecasting\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     32\u001B[0m     GRU,\n\u001B[0;32m     33\u001B[0m     LSTM,\n\u001B[0;32m     34\u001B[0m     AutoRegressiveBaseModel,\n\u001B[0;32m     35\u001B[0m     AutoRegressiveBaseModelWithCovariates,\n\u001B[0;32m     36\u001B[0m     Baseline,\n\u001B[0;32m     37\u001B[0m     BaseModel,\n\u001B[0;32m     38\u001B[0m     BaseModelWithCovariates,\n\u001B[0;32m     39\u001B[0m     DecoderMLP,\n\u001B[0;32m     40\u001B[0m     DeepAR,\n\u001B[0;32m     41\u001B[0m     MultiEmbedding,\n\u001B[0;32m     42\u001B[0m     NBeats,\n\u001B[0;32m     43\u001B[0m     NHiTS,\n\u001B[0;32m     44\u001B[0m     RecurrentNetwork,\n\u001B[0;32m     45\u001B[0m     TemporalFusionTransformer,\n\u001B[0;32m     46\u001B[0m     get_rnn,\n\u001B[0;32m     47\u001B[0m )\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_forecasting\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     49\u001B[0m     apply_to_list,\n\u001B[0;32m     50\u001B[0m     autocorrelation,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     59\u001B[0m     unpack_sequence,\n\u001B[0;32m     60\u001B[0m )\n\u001B[0;32m     62\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTimeSeriesDataSet\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     64\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGroupNormalizer\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    111\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munpack_sequence\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    112\u001B[0m ]\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv10\\lib\\site-packages\\pytorch_forecasting\\models\\__init__.py:4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03mModels for timeseries forecasting.\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_forecasting\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      5\u001B[0m     AutoRegressiveBaseModel,\n\u001B[0;32m      6\u001B[0m     AutoRegressiveBaseModelWithCovariates,\n\u001B[0;32m      7\u001B[0m     BaseModel,\n\u001B[0;32m      8\u001B[0m     BaseModelWithCovariates,\n\u001B[0;32m      9\u001B[0m )\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_forecasting\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbaseline\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Baseline\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_forecasting\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdeepar\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DeepAR\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv10\\lib\\site-packages\\pytorch_forecasting\\models\\base_model.py:20\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunction_base\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m iterable\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpytorch_optimizer\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'numpy.lib.function_base'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def log_imputation(method_name, impute_function, df):\n",
    "    df_imputed = impute_function(df)\n",
    "    logging.info(f\"Imputação realizada usando: {method_name}\")\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def Mice_imputer(df):\n",
    "    mice_imputer = IterativeImputer(\n",
    "        estimator=ExtraTreesRegressor(n_estimators=100, random_state=42),\n",
    "        max_iter=10,\n",
    "        random_state=42,\n",
    "        n_nearest_features=None,\n",
    "        initial_strategy='mean'\n",
    "    )\n",
    "\n",
    "    df_imputed = pd.DataFrame(\n",
    "        mice_imputer.fit_transform(df),\n",
    "        columns=df.columns,\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def mean_imputer(df):\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    df_imputed = pd.DataFrame(\n",
    "        imputer.fit_transform(df),\n",
    "        columns=df.columns,\n",
    "        index=df.index\n",
    "    )\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def median_imputer(df):\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    df_imputed = pd.DataFrame(\n",
    "        imputer.fit_transform(df),\n",
    "        columns=df.columns,\n",
    "        index=df.index\n",
    "    )\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def forward_fill_imputer(df):\n",
    "    df_imputed = df.fillna(method='ffill')\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def backward_fill_imputer(df):\n",
    "    df_imputed = df.fillna(method='bfill')\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def linear_interpolation_imputer(df):\n",
    "    df_imputed = df.interpolate(method='linear')\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def exponential_smoothing_imputer(df):\n",
    "    df_imputed = df.ewm(alpha=0.5).mean()\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def knn_imputer(df):\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    df_imputed = pd.DataFrame(\n",
    "        imputer.fit_transform(df),\n",
    "        columns=df.columns,\n",
    "        index=df.index\n",
    "    )\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "# df_imputed = log_imputation('Mean', mean_imputer, df)\n",
    "# df_imputed = log_imputation('Median', median_imputer, df)\n",
    "# df_imputed = log_imputation('Forward Fill', forward_fill_imputer, df)\n",
    "# df_imputed = log_imputation('Backward Fill', backward_fill_imputer, df)\n",
    "# df_imputed = log_imputation('Linear Interpolation', linear_interpolation_imputer, df)\n",
    "# df_imputed = log_imputation('Exponential Smoothing', exponential_smoothing_imputer, df)\n",
    "# df_imputed = log_imputation('KNN', knn_imputer, df)\n",
    "df_imputed = log_imputation('MICE', Mice_imputer, df)\n"
   ],
   "id": "653a60c672216ebb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Preparando os dados para o TFT\n",
    "max_prediction_length = 24  # Previsão para as próximas 24 horas\n",
    "max_encoder_length = 168  # Usar uma semana de dados históricos\n",
    "\n",
    "df_imputed = df_imputed.reset_index()\n",
    "df_imputed['time_idx'] = df_imputed.index\n",
    "\n",
    "# Adicionando variáveis de tempo\n",
    "df_imputed['hour'] = df_imputed['Data e Hora'].dt.hour\n",
    "df_imputed['dayofweek'] = df_imputed['Data e Hora'].dt.dayofweek\n",
    "df_imputed['month'] = df_imputed['Data e Hora'].dt.month\n",
    "\n",
    "# Definindo variáveis categóricas e contínuas\n",
    "static_categoricals = []\n",
    "static_reals = []\n",
    "time_varying_known_reals = ['hour', 'dayofweek', 'month']\n",
    "time_varying_unknown_reals = ['PM10', 'Monóxido de Carbono']\n",
    "\n",
    "# Criando o conjunto de dados do TimeSeriesDataSet\n",
    "training_cutoff = df_imputed['time_idx'].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    df_imputed[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx='time_idx',\n",
    "    target='PM2.5',\n",
    "    group_ids=['Data e Hora'],\n",
    "    static_categoricals=static_categoricals,\n",
    "    static_reals=static_reals,\n",
    "    time_varying_known_reals=time_varying_known_reals,\n",
    "    time_varying_unknown_reals=time_varying_unknown_reals,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    ")\n",
    "\n",
    "# Criando os conjuntos de validação e teste\n",
    "validation = TimeSeriesDataSet.from_dataset(training, df_imputed, predict=True, stop_randomization=True)\n",
    "batch_size = 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n",
    "\n",
    "# Função para otimizar os hiperparâmetros\n",
    "def optimize_tft(trial):\n",
    "    params = {\n",
    "        \"hidden_size\": trial.suggest_int(\"hidden_size\", 16, 128),\n",
    "        \"lstm_layers\": trial.suggest_int(\"lstm_layers\", 1, 5),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True),\n",
    "        \"hidden_continuous_size\": trial.suggest_int(\"hidden_continuous_size\", 8, 64),\n",
    "        \"attention_head_size\": trial.suggest_int(\"attention_head_size\", 1, 4),\n",
    "    }\n",
    "    \n",
    "    model = TemporalFusionTransformer.from_dataset(\n",
    "        training,\n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    # Treinamento e avaliação\n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=100,\n",
    "        gpus=0,\n",
    "        gradient_clip_val=0.1,\n",
    "        callbacks=[early_stop_callback],\n",
    "    )\n",
    "    trainer.fit(\n",
    "        model,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )\n",
    "    \n",
    "    return trainer.callback_metrics[\"val_loss\"].item()\n",
    "\n",
    "# Otimização dos hiperparâmetros\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(optimize_tft, n_trials=50)\n",
    "\n",
    "# Obtendo os melhores hiperparâmetros\n",
    "best_params = study.best_params\n",
    "print(\"Melhores hiperparâmetros:\", best_params)\n",
    "\n",
    "# Criando o modelo final com os melhores hiperparâmetros\n",
    "final_model = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "# Treinamento do modelo final\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=50, verbose=False, mode=\"min\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=500,\n",
    "    gpus=0,\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[early_stop_callback],\n",
    ")\n",
    "trainer.fit(\n",
    "    final_model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")\n",
    "\n",
    "# Salvando o modelo final\n",
    "torch.save(final_model.state_dict(), f'../best_models/{data_hoje}/best_tft_model.pth')\n",
    "\n",
    "# Avaliação do modelo\n",
    "predictions = final_model.predict(val_dataloader)\n",
    "actuals = torch.cat([y for x, y in iter(val_dataloader)])\n",
    "\n",
    "mae = MAE()(predictions, actuals)\n",
    "smape = SMAPE()(predictions, actuals)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"SMAPE: {smape:.4f}\")"
   ],
   "id": "79ab8ce845cbf548",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ce2d28fca0da4981",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
