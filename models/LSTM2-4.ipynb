{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Melhor modelo LSTM padrao ate o momento R2 de .71",
   "id": "dddff4c9c88ebe58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T21:27:10.853469Z",
     "start_time": "2024-09-01T21:27:10.849641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sympy import false\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from copy import deepcopy as dc\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import optuna\n",
    "import torch.nn.functional as F\n",
    "import os"
   ],
   "id": "1ab0f1299a77df43",
   "outputs": [],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T21:27:11.184892Z",
     "start_time": "2024-09-01T21:27:10.943862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuração inicial\n",
    "data_hoje = datetime.now().strftime('%d-%m')\n",
    "inicio_execucao = pd.Timestamp.now()\n",
    "\n",
    "# Criando diretórios para logs e plots\n",
    "os.makedirs(f'../logs/{data_hoje}', exist_ok=True)\n",
    "os.makedirs(f'../plots/{data_hoje}', exist_ok=True)\n",
    "\n",
    "# Configuração do logging\n",
    "logging.basicConfig(filename=f'../logs/{data_hoje}/lstm_optuna.log', level=logging.INFO, format='- %(message)s')\n",
    "logging.info('-' * 50)\n",
    "logging.info(f'{inicio_execucao} - Iniciando o processo de otimização e treinamento do modelo LSTM')\n",
    "\n",
    "# Carregando e preparando os dados\n",
    "df_original = pd.read_csv('../dados_tratados/combinado/Piratininga/Piratininga_tratado_combinado.csv',\n",
    "                          usecols=['PM2.5', 'Data e Hora', 'PM10', 'Monóxido de Carbono'], low_memory=False)\n",
    "\n",
    "df_original['Data e Hora'] = pd.to_datetime(df_original['Data e Hora'])\n",
    "df_original.set_index('Data e Hora', inplace=True)\n",
    "df_original.sort_index(inplace=True)\n",
    "\n",
    "colunas_selecionadas = ['PM2.5', 'PM10', 'Monóxido de Carbono']\n",
    "logging.info(f\"Colunas selecionadas: {colunas_selecionadas}\")\n",
    "df = df_original[colunas_selecionadas]\n",
    "df = df.loc['2019-01-01':'2022-01-01']\n",
    "\n",
    "df = df.apply(pd.to_numeric, errors='coerce')"
   ],
   "id": "418fe42641446a0",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T21:27:11.199444Z",
     "start_time": "2024-09-01T21:27:11.188418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def treat_outliers(df):\n",
    "    for column in df.columns:\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])\n",
    "        df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])\n",
    "    return df\n",
    "\n",
    "\n",
    "# fazendo o logging de qual algoritmo de imputação foi utilizado\n",
    "def log_imputation(method_name, impute_function, df):\n",
    "    df_imputed = impute_function(df)\n",
    "    logging.info(f\"Imputação realizada usando: {method_name}\")\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "# Função para imputação de dados ausentes\n",
    "def backward_fill_imputer(df):\n",
    "    df_imputed = df.fillna(method='bfill')\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "#mean imputation using the 24h mean\n",
    "def mean_imputation(df):\n",
    "    df_imputed = df.fillna(df.rolling(window=24, min_periods=1).mean())\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def linear_interpolation_imputer(df):\n",
    "    df_imputed = df.interpolate(method='linear')\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "# df_imputed = log_imputation('Backward Fill', backward_fill_imputer, df)\n",
    "df_imputed = log_imputation('Linear Interpolation', linear_interpolation_imputer, df)\n",
    "# df_imputed = log_imputation('Mean Imputation 24h', mean_imputation, df)\n",
    "\n",
    "logging.info(f\"Dados ausentes antes da imputação: {df.isna().sum()}\")\n",
    "logging.info(f\"Dados ausentes após a imputação: {df_imputed.isna().sum()}\")\n",
    "\n",
    "# treating outliers\n",
    "# df = treat_outliers(df)"
   ],
   "id": "65334a755512eced",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T21:27:11.307747Z",
     "start_time": "2024-09-01T21:27:11.278838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preparando os dados para LSTM\n",
    "def prepare_dataframe_for_lstm(df, n_steps):\n",
    "    df = dc(df)\n",
    "    for col in colunas_selecionadas:\n",
    "        for i in range(1, n_steps + 1):\n",
    "            df[f'{col}(t-{i})'] = df[col].shift(i)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "lookback = 8\n",
    "shifted_df = prepare_dataframe_for_lstm(df_imputed, lookback)\n",
    "\n",
    "# Dividindo em conjuntos de treino, validação e teste\n",
    "train_size = int(len(shifted_df) * 0.7)\n",
    "val_size = int(len(shifted_df) * 0.15)\n",
    "\n",
    "train_df = shifted_df.iloc[:train_size]\n",
    "val_df = shifted_df.iloc[train_size:train_size + val_size]\n",
    "test_df = shifted_df.iloc[train_size + val_size:]\n",
    "\n",
    "# Normalizando os dados de forma correta\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_scaled = pd.DataFrame(scaler.fit_transform(train_df), columns=shifted_df.columns, index=train_df.index)\n",
    "val_scaled = pd.DataFrame(scaler.transform(val_df), columns=shifted_df.columns, index=val_df.index)\n",
    "test_scaled = pd.DataFrame(scaler.transform(test_df), columns=shifted_df.columns, index=test_df.index)\n",
    "\n",
    "X_train, y_train = train_scaled.iloc[:, len(colunas_selecionadas):].values, train_scaled.iloc[:, 0].values\n",
    "X_val, y_val = val_scaled.iloc[:, len(colunas_selecionadas):].values, val_scaled.iloc[:, 0].values\n",
    "X_test, y_test = test_scaled.iloc[:, len(colunas_selecionadas):].values, test_scaled.iloc[:, 0].values\n",
    "\n",
    "# Reshape para LSTM\n",
    "X_train = X_train.reshape((-1, lookback, len(colunas_selecionadas)))\n",
    "X_val = X_val.reshape((-1, lookback, len(colunas_selecionadas)))\n",
    "X_test = X_test.reshape((-1, lookback, len(colunas_selecionadas)))\n",
    "y_train = y_train.reshape((-1, 1))\n",
    "y_val = y_val.reshape((-1, 1))\n",
    "y_test = y_test.reshape((-1, 1))\n",
    "\n",
    "# Convertendo para tensores PyTorch\n",
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train).float()\n",
    "X_val = torch.tensor(X_val).float()\n",
    "y_val = torch.tensor(y_val).float()\n",
    "X_test = torch.tensor(X_test).float()\n",
    "y_test = torch.tensor(y_test).float()\n",
    "\n",
    "\n",
    "# Dataset e DataLoader\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "\n",
    "# Modelo LSTM\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ],
   "id": "dd40f0a27c8b6d44",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T21:27:11.398188Z",
     "start_time": "2024-09-01T21:27:11.390202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_size // num_heads\n",
    "\n",
    "        self.query = nn.Linear(hidden_size, hidden_size)\n",
    "        self.key = nn.Linear(hidden_size, hidden_size)\n",
    "        self.value = nn.Linear(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        q = self.query(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = self.key(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = self.value(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.matmul(attention_weights, v)\n",
    "\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.hidden_size)\n",
    "        output = self.out(context)\n",
    "        return output\n",
    "\n",
    "class ImprovedLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.attention = MultiHeadAttention(hidden_size * 2, num_heads)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size * 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # LSTM layers\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Apply attention\n",
    "        attn_out = self.attention(lstm_out)\n",
    "        \n",
    "        # Add & Norm\n",
    "        out = self.layer_norm(lstm_out + attn_out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Global average pooling\n",
    "        out = torch.mean(out, dim=1)\n",
    "        \n",
    "        # Final prediction\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ],
   "id": "8d8cbc463f878c02",
   "outputs": [],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T21:27:11.482800Z",
     "start_time": "2024-09-01T21:27:11.474205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# Função de treinamento\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, device):\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Treinamento\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Validação\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "                output = model(x_batch)\n",
    "                val_loss += criterion(output, y_batch).item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        # Ajuste da taxa de aprendizagem\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # logging.info(f\"Época {epoch + 1}/{num_epochs}, Perda de treino: {train_loss:.4f}, Perda de validação: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            logging.info(f\"Early stopping ativado na época {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    # Carregar o melhor modelo\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model"
   ],
   "id": "4bbba2f5ba37fc6b",
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T21:27:11.564449Z",
     "start_time": "2024-09-01T21:27:11.558907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    hidden_size = trial.suggest_int('hidden_size', 32, 256)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    num_heads = trial.suggest_int('num_heads', 1, 8)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "\n",
    "    train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "    val_dataset = TimeSeriesDataset(X_val, y_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    input_size = X_train.shape[2]\n",
    "    model = ImprovedLSTM(input_size, hidden_size, num_layers, num_heads, dropout).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    criterion = nn.HuberLoss()\n",
    "\n",
    "    num_epochs = 100\n",
    "    early_stopping_patience = 10\n",
    "\n",
    "    model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, early_stopping_patience, device)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "            output = model(x_batch)\n",
    "            val_loss += criterion(output, y_batch).item()\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    return val_loss"
   ],
   "id": "5b1ce00606d3df1",
   "outputs": [],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T21:30:14.525855Z",
     "start_time": "2024-09-01T21:27:11.634501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=20)  # Reduced number of trials for quicker results\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "best_hidden_sizes = [best_params[f'hidden_size_{i}'] for i in range(best_params['num_layers'])]\n",
    "best_batch_size = best_params['batch_size']\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "val_dataset = TimeSeriesDataset(X_val, y_val)\n",
    "test_dataset = TimeSeriesDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=best_batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_batch_size, shuffle=False)\n",
    "\n",
    "final_model = ImprovedLSTM(X_train.shape[2], best_hidden_sizes, best_params['num_heads'], best_params['dropout']).to(device)\n",
    "optimizer = torch.optim.AdamW(final_model.parameters(), lr=best_params['learning_rate'], weight_decay=best_params['weight_decay'])\n",
    "criterion = nn.HuberLoss()\n",
    "\n",
    "num_epochs = 100\n",
    "patience = 10\n",
    "\n",
    "final_model = train_model(final_model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, device)\n",
    "\n",
    "# Salvar o modelo final\n",
    "torch.save(final_model.state_dict(), f'../models/best_model_optuna_{data_hoje}.pth')\n",
    "\n",
    "\n",
    "# Avaliação final\n",
    "def evaluate(model, dataloader):\n",
    "    predictions = []\n",
    "    actual = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "            output = model(x_batch)\n",
    "            predictions.extend(output.cpu().numpy().flatten())\n",
    "            actual.extend(y_batch.cpu().numpy().flatten())\n",
    "    return np.array(predictions), np.array(actual)\n",
    "\n",
    "\n",
    "train_predictions, train_actual = evaluate(final_model, train_loader)\n",
    "val_predictions, val_actual = evaluate(final_model, val_loader)\n",
    "test_predictions, test_actual = evaluate(final_model, test_loader)"
   ],
   "id": "f608d404a5cd2463",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-01 18:27:11,639] A new study created in memory with name: no-name-fa00a062-6655-4d56-9c15-377105823304\n",
      "C:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "[I 2024-09-01 18:30:14,400] Trial 0 finished with value: 0.0007350033908639284 and parameters: {'hidden_size': 68, 'num_layers': 3, 'num_heads': 4, 'batch_size': 128, 'learning_rate': 0.003090445301104967, 'dropout': 0.48371815223298087, 'weight_decay': 3.945614028346779e-05}. Best is trial 0 with value: 0.0007350033908639284.\n",
      "[W 2024-09-01 18:30:14,416] Trial 1 failed with parameters: {'hidden_size': 245, 'num_layers': 1, 'num_heads': 6, 'batch_size': 32, 'learning_rate': 0.0014616317229014918, 'dropout': 0.3509789337039221, 'weight_decay': 6.189184384966231e-05} because of the following error: RuntimeError(\"shape '[32, 8, 6, 81]' is invalid for input of size 125440\").\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\portes\\AppData\\Local\\Temp\\ipykernel_23428\\2741656813.py\", line 23, in objective\n",
      "    model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, early_stopping_patience, device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\portes\\AppData\\Local\\Temp\\ipykernel_23428\\3270452302.py\", line 20, in train_model\n",
      "    output = model(x_batch)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\portes\\AppData\\Local\\Temp\\ipykernel_23428\\2003805058.py\", line 52, in forward\n",
      "    attn_out = self.attention(lstm_out)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\portes\\AppData\\Local\\Temp\\ipykernel_23428\\2003805058.py\", line 20, in forward\n",
      "    q = self.query(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: shape '[32, 8, 6, 81]' is invalid for input of size 125440\n",
      "[W 2024-09-01 18:30:14,417] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[32, 8, 6, 81]' is invalid for input of size 125440",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[132], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mminimize\u001B[39m\u001B[38;5;124m'\u001B[39m, sampler\u001B[38;5;241m=\u001B[39moptuna\u001B[38;5;241m.\u001B[39msamplers\u001B[38;5;241m.\u001B[39mTPESampler())\n\u001B[1;32m----> 2\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Reduced number of trials for quicker results\u001B[39;00m\n\u001B[0;32m      4\u001B[0m best_params \u001B[38;5;241m=\u001B[39m study\u001B[38;5;241m.\u001B[39mbest_params\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest hyperparameters: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbest_params\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\optuna\\study\\study.py:451\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    348\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[0;32m    349\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    350\u001B[0m     func: ObjectiveFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    357\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    358\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    359\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[0;32m    360\u001B[0m \n\u001B[0;32m    361\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    449\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[0;32m    450\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 451\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    453\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    454\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    455\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    456\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    458\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    459\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    461\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001B[0m, in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 62\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     63\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     64\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     75\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    156\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 159\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    161\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[0;32m    162\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[0;32m    164\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    240\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    242\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    243\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[0;32m    244\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[0;32m    246\u001B[0m ):\n\u001B[1;32m--> 247\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[0;32m    248\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[0;32m    195\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 196\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    198\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[0;32m    199\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[1;32mIn[131], line 23\u001B[0m, in \u001B[0;36mobjective\u001B[1;34m(trial)\u001B[0m\n\u001B[0;32m     20\u001B[0m num_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[0;32m     21\u001B[0m early_stopping_patience \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[1;32m---> 23\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stopping_patience\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m     26\u001B[0m val_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n",
      "Cell \u001B[1;32mIn[130], line 20\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, device)\u001B[0m\n\u001B[0;32m     18\u001B[0m x_batch, y_batch \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device), batch[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     19\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 20\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(output, y_batch)\n\u001B[0;32m     22\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[129], line 52\u001B[0m, in \u001B[0;36mImprovedLSTM.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     49\u001B[0m lstm_out, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlstm(x)\n\u001B[0;32m     51\u001B[0m \u001B[38;5;66;03m# Apply attention\u001B[39;00m\n\u001B[1;32m---> 52\u001B[0m attn_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlstm_out\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;66;03m# Add & Norm\u001B[39;00m\n\u001B[0;32m     55\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer_norm(lstm_out \u001B[38;5;241m+\u001B[39m attn_out)\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[129], line 20\u001B[0m, in \u001B[0;36mMultiHeadAttention.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m     18\u001B[0m     batch_size, seq_len, _ \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39msize()\n\u001B[1;32m---> 20\u001B[0m     q \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseq_len\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_heads\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhead_dim\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     21\u001B[0m     k \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkey(x)\u001B[38;5;241m.\u001B[39mview(batch_size, seq_len, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead_dim)\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     22\u001B[0m     v \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalue(x)\u001B[38;5;241m.\u001B[39mview(batch_size, seq_len, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead_dim)\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: shape '[32, 8, 6, 81]' is invalid for input of size 125440"
     ]
    }
   ],
   "execution_count": 132
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Desnormalização\n",
    "def inverse_transform_data(normalized_data):\n",
    "    # Criar um array de zeros com o mesmo número de colunas que os dados originais\n",
    "    dummy_array = np.zeros((len(normalized_data), len(shifted_df.columns)))\n",
    "\n",
    "    # Colocar os dados normalizados na primeira coluna (assumindo que é PM2.5)\n",
    "    dummy_array[:, 0] = normalized_data\n",
    "\n",
    "    # Aplicar a transformação inversa\n",
    "    denormalized_data = scaler.inverse_transform(dummy_array)\n",
    "\n",
    "    # Retornar apenas a primeira coluna, que contém os dados desnormalizados de interesse\n",
    "    return denormalized_data[:, 0]\n",
    "\n",
    "\n",
    "# Desnormalização das previsões e valores reais\n",
    "train_predictions = inverse_transform_data(train_predictions)\n",
    "val_predictions = inverse_transform_data(val_predictions)\n",
    "test_predictions = inverse_transform_data(test_predictions)\n",
    "\n",
    "# Para os valores reais, precisamos garantir que estamos usando os dados originais não normalizados\n",
    "train_actual = df_imputed['PM2.5'].values[:len(train_predictions)]\n",
    "val_actual = df_imputed['PM2.5'].values[len(train_predictions):len(train_predictions) + len(val_predictions)]\n",
    "test_actual = df_imputed['PM2.5'].values[-len(test_predictions):]\n",
    "\n",
    "\n",
    "# Cálculo das métricas\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return rmse, mse, mae, r2, mape\n",
    "\n",
    "\n",
    "# Calcular métricas\n",
    "train_rmse, train_mse, train_mae, train_r2, train_mape = calculate_metrics(train_actual, train_predictions)\n",
    "val_rmse, val_mse, val_mae, val_r2, val_mape = calculate_metrics(val_actual, val_predictions)\n",
    "test_rmse, test_mse, test_mae, test_r2, test_mape = calculate_metrics(test_actual, test_predictions)\n",
    "\n",
    "# Logging dos resultados\n",
    "logging.info(\n",
    "    f\"Métricas de Treino: RMSE={train_rmse:.4f}, MSE={train_mse:.4f}, MAE={train_mae:.4f}, R2={train_r2:.4f}, MAPE={train_mape:.4f}\")\n",
    "logging.info(\n",
    "    f\"Métricas de Validação: RMSE={val_rmse:.4f}, MSE={val_mse:.4f}, MAE={val_mae:.4f}, R2={val_r2:.4f}, MAPE={val_mape:.4f}\")\n",
    "logging.info(\n",
    "    f\"Métricas de Teste: RMSE={test_rmse:.4f}, MSE={test_mse:.4f}, MAE={test_mae:.4f}, R2={test_r2:.4f}, MAPE={test_mape:.4f}\")"
   ],
   "id": "8ed03d304545ce81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Log das métricas finais\n",
    "logging.info(\"\\nMétricas finais:\")\n",
    "logging.info(\"Treinamento - RMSE: {:.4f}, MSE: {:.4f}, MAE: {:.4f}, R²: {:.4f}\".format(train_rmse, train_mse, train_mae,\n",
    "                                                                                       train_r2))\n",
    "logging.info(\n",
    "    \"Validação - RMSE: {:.4f}, MSE: {:.4f}, MAE: {:.4f}, R²: {:.4f}\".format(val_rmse, val_mse, val_mae, val_r2))\n",
    "logging.info(\n",
    "    \"Teste - RMSE: {:.4f}, MSE: {:.4f}, MAE: {:.4f}, R²: {:.4f}\".format(test_rmse, test_mse, test_mae, test_r2))\n",
    "\n",
    "# Plotagem dos resultados\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_actual, label='Actual PM2.5')\n",
    "plt.plot(train_predictions, label='Predicted PM2.5')\n",
    "plt.title('Treinamento: PM2.5 Real vs Previsto')\n",
    "plt.xlabel('Hora')\n",
    "plt.ylabel('PM2.5')\n",
    "plt.legend()\n",
    "plt.savefig(f'../plots/{data_hoje}/lstm_optuna_train_{data_hoje}.png')\n"
   ],
   "id": "60faf0cdcf264037",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "train_dates = shifted_df.index[:len(train_actual)]\n",
    "val_dates = shifted_df.index[len(train_actual):len(train_actual) + len(val_actual)]\n",
    "test_dates = shifted_df.index[-len(test_actual):]\n",
    "\n",
    "\n",
    "def plot_results(actual, predicted, dates, title, filename):\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.plot(dates, actual, label='Real', color='blue')\n",
    "    plt.plot(dates, predicted, label='Previsto', color='red')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Data')\n",
    "    plt.ylabel('PM2.5')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))  # Mostrar a cada 3 meses\n",
    "\n",
    "    plt.gcf().autofmt_xdate()  # Rotacionar e alinhar os rótulos de data\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../plots/{data_hoje}/{filename}_{data_hoje}.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "plot_results(train_actual, train_predictions, train_dates, 'Treinamento: PM2.5 Real vs Previsto', 'lstm_optuna_train')\n",
    "plot_results(val_actual, val_predictions, val_dates, 'Validação: PM2.5 Real vs Previsto', 'lstm_optuna_val')\n",
    "plot_results(test_actual, test_predictions, test_dates, 'Teste: PM2.5 Real vs Previsto', 'lstm_optuna_test')\n",
    "\n",
    "fim_execucao = pd.Timestamp.now()\n",
    "tempo_execucao = fim_execucao - inicio_execucao\n",
    "logging.info(f\"\\nExecução finalizada em {fim_execucao}\")\n",
    "logging.info(f\"Tempo total de execução: {tempo_execucao}\")"
   ],
   "id": "19edab1f2a08d516",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_results_by_month(actual, predicted, dates, title_prefix, filename_prefix):\n",
    "    df = pd.DataFrame({'date': dates, 'actual': actual, 'predicted': predicted})\n",
    "    df.set_index('date', inplace=True)\n",
    "\n",
    "    grouped = df.groupby(pd.Grouper(freq='M'))\n",
    "\n",
    "    for name, group in grouped:\n",
    "        if len(group) > 0:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(group.index, group['actual'], label='Real', color='blue')\n",
    "            plt.plot(group.index, group['predicted'], label='Previsto', color='red')\n",
    "\n",
    "            month_year = name.strftime('%B %Y')\n",
    "            plt.title(f'{title_prefix} - {month_year}')\n",
    "            plt.xlabel('Data')\n",
    "            plt.ylabel('PM2.5')\n",
    "            plt.legend()\n",
    "\n",
    "            plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d-%m'))\n",
    "            plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=5))\n",
    "\n",
    "            plt.gcf().autofmt_xdate()  # Rotacionar e alinhar os rótulos de data\n",
    "            plt.tight_layout()\n",
    "\n",
    "            month_filename = f'{filename_prefix}_{name.strftime(\"%Y_%m\")}_{data_hoje}.png'\n",
    "            plt.savefig(f'../plots/{data_hoje}/{month_filename}')\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "plot_results_by_month(train_actual, train_predictions, train_dates, 'Treinamento: PM2.5 Real vs Previsto',\n",
    "                      'lstm_optuna_train')\n",
    "plot_results_by_month(val_actual, val_predictions, val_dates, 'Validação: PM2.5 Real vs Previsto', 'lstm_optuna_val')\n",
    "plot_results_by_month(test_actual, test_predictions, test_dates, 'Teste: PM2.5 Real vs Previsto', 'lstm_optuna_test')"
   ],
   "id": "5d311845f2a60318",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
