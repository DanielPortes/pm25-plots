{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Melhor modelo LSTM padrao ate o momento R2 de .71",
   "id": "dddff4c9c88ebe58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T21:09:23.991748Z",
     "start_time": "2024-09-16T21:09:23.938744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sympy import false\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from copy import deepcopy as dc\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import optuna\n",
    "import torch.nn.functional as F\n",
    "import os"
   ],
   "id": "1ab0f1299a77df43",
   "outputs": [],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T21:09:24.474592Z",
     "start_time": "2024-09-16T21:09:23.998263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuração inicial\n",
    "data_hoje = datetime.now().strftime('%d-%m')\n",
    "inicio_execucao = pd.Timestamp.now()\n",
    "\n",
    "# Criando diretórios para logs e plots\n",
    "os.makedirs(f'../logs/{data_hoje}', exist_ok=True)\n",
    "os.makedirs(f'../plots/{data_hoje}', exist_ok=True)\n",
    "\n",
    "# Configuração do logging\n",
    "logging.basicConfig(filename=f'../logs/{data_hoje}/lstm_optuna.log', level=logging.INFO, format='- %(message)s')\n",
    "logging.info('-' * 50)\n",
    "logging.info(f'{inicio_execucao} - Iniciando o processo de otimização e treinamento do modelo LSTM')\n",
    "\n",
    "# Carregando e preparando os dados\n",
    "df_original = pd.read_csv('../dados_tratados/combinado/Piratininga/Piratininga_tratado_combinado.csv',\n",
    "                          usecols=['PM2.5', 'Data e Hora', 'PM10', 'Monóxido de Carbono'], low_memory=False)\n",
    "\n",
    "df_original['Data e Hora'] = pd.to_datetime(df_original['Data e Hora'])\n",
    "df_original.set_index('Data e Hora', inplace=True)\n",
    "df_original.sort_index(inplace=True)\n",
    "\n",
    "colunas_selecionadas = ['PM2.5', 'PM10', 'Monóxido de Carbono']\n",
    "logging.info(f\"Colunas selecionadas: {colunas_selecionadas}\")\n",
    "df = df_original[colunas_selecionadas]\n",
    "df = df.loc['2019-01-01':'2022-01-01']\n",
    "\n",
    "df = df.apply(pd.to_numeric, errors='coerce')"
   ],
   "id": "418fe42641446a0",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T21:09:24.692710Z",
     "start_time": "2024-09-16T21:09:24.680092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fazendo o logging de qual algoritmo de imputação foi utilizado\n",
    "def log_imputation(method_name, impute_function, df):\n",
    "    df_imputed = impute_function(df)\n",
    "    logging.info(f\"Imputação realizada usando: {method_name}\")\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def linear_interpolation_imputer(df):\n",
    "    df_imputed = df.interpolate(method='linear')\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "df_imputed = log_imputation('Linear Interpolation', linear_interpolation_imputer, df)\n",
    "\n",
    "logging.info(f\"Dados ausentes antes da imputação: {df.isna().sum()}\")\n",
    "logging.info(f\"Dados ausentes após a imputação: {df_imputed.isna().sum()}\")\n",
    "logging.info(f\"Dados totais: {len(df_imputed)}\")"
   ],
   "id": "65334a755512eced",
   "outputs": [],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T21:09:24.831848Z",
     "start_time": "2024-09-16T21:09:24.772154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Preparando os dados para LSTM\n",
    "def prepare_dataframe_for_lstm(df, n_steps, colunas_selecionadas):\n",
    "    df = dc(df)\n",
    "    new_columns = {}\n",
    "    for col in colunas_selecionadas:\n",
    "        for i in range(1, n_steps + 1):\n",
    "            new_columns[f'{col}(t-{i})'] = df[col].shift(i)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_columns)], axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "lookback_in_hours = 8\n",
    "shifted_df = prepare_dataframe_for_lstm(df_imputed, lookback_in_hours, colunas_selecionadas)\n",
    "\n",
    "# Dividindo em conjuntos de treino, validação e teste\n",
    "train_size = int(len(shifted_df) * 0.7)\n",
    "val_size = int(len(shifted_df) * 0.15)\n",
    "\n",
    "train_df = shifted_df.iloc[:train_size]\n",
    "val_df = shifted_df.iloc[train_size:train_size + val_size]\n",
    "test_df = shifted_df.iloc[train_size + val_size:]\n",
    "\n",
    "# Normalizando os dados de forma correta\n",
    "scaler = StandardScaler()\n",
    "train_scaled = pd.DataFrame(scaler.fit_transform(train_df), columns=shifted_df.columns, index=train_df.index)\n",
    "val_scaled = pd.DataFrame(scaler.transform(val_df), columns=shifted_df.columns, index=val_df.index)\n",
    "test_scaled = pd.DataFrame(scaler.transform(test_df), columns=shifted_df.columns, index=test_df.index)\n",
    "\n",
    "X_train, y_train = train_scaled.iloc[:, len(colunas_selecionadas):].values, train_scaled.iloc[:, 0].values\n",
    "X_val, y_val = val_scaled.iloc[:, len(colunas_selecionadas):].values, val_scaled.iloc[:, 0].values\n",
    "X_test, y_test = test_scaled.iloc[:, len(colunas_selecionadas):].values, test_scaled.iloc[:, 0].values\n",
    "\n",
    "# Reshape para LSTM\n",
    "X_train = X_train.reshape((-1, lookback_in_hours, len(colunas_selecionadas)))\n",
    "X_val = X_val.reshape((-1, lookback_in_hours, len(colunas_selecionadas)))\n",
    "X_test = X_test.reshape((-1, lookback_in_hours, len(colunas_selecionadas)))\n",
    "y_train = y_train.reshape((-1, 1))\n",
    "y_val = y_val.reshape((-1, 1))\n",
    "y_test = y_test.reshape((-1, 1))\n",
    "\n",
    "# Convertendo para tensores PyTorch\n",
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train).float()\n",
    "X_val = torch.tensor(X_val).float()\n",
    "y_val = torch.tensor(y_val).float()\n",
    "X_test = torch.tensor(X_test).float()\n",
    "y_test = torch.tensor(y_test).float()\n",
    "\n",
    "\n",
    "# Dataset e DataLoader\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "\n",
    "# Modelo LSTM\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ],
   "id": "f7d2cab8b34d6d8d",
   "outputs": [],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T21:09:24.944033Z",
     "start_time": "2024-09-16T21:09:24.929250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention_weights = nn.Parameter(torch.randn(hidden_size))\n",
    "\n",
    "    def forward(self, lstm_output):\n",
    "        attention_scores = torch.tanh(torch.matmul(lstm_output, self.attention_weights))\n",
    "        attention_scores = F.softmax(attention_scores, dim=1)\n",
    "        weighted_output = torch.mul(lstm_output, attention_scores.unsqueeze(-1))\n",
    "        return weighted_output.sum(dim=1)\n",
    "\n",
    "\n",
    "class LSTM_MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, mlp_sizes, activation, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.num_lstm_layers = len(hidden_sizes)\n",
    "        self.activation = activation\n",
    "\n",
    "        # Bidirectional LSTM Encoder\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_sizes[-1],\n",
    "            num_layers=self.num_lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if self.num_lstm_layers > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.attention = Attention(hidden_sizes[-1] * 2)  # *2 for bidirectional\n",
    "\n",
    "        # MLP Decoder\n",
    "        mlp_layers = []\n",
    "        in_features = hidden_sizes[-1] * 2  # *2 for bidirectional\n",
    "        for out_features in mlp_sizes:\n",
    "            mlp_layers.append(nn.Linear(in_features, out_features))\n",
    "            mlp_layers.append(self.get_activation())\n",
    "            mlp_layers.append(nn.Dropout(dropout))\n",
    "            in_features = out_features\n",
    "        mlp_layers.append(nn.Linear(in_features, 1))  # Output layer\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        attended_output = self.attention(lstm_out)\n",
    "        out = self.mlp(attended_output)\n",
    "        return out\n",
    "\n",
    "    def get_activation(self):\n",
    "        activations = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(),\n",
    "            'elu': nn.ELU(),\n",
    "            'sigmoid': nn.Sigmoid(),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'swish': nn.SiLU(),\n",
    "            'mish': nn.Mish(),\n",
    "            'gelu': nn.GELU(),\n",
    "            'softplus': nn.Softplus()\n",
    "        }\n",
    "        return activations.get(self.activation, nn.Identity())\n"
   ],
   "id": "8d8cbc463f878c02",
   "outputs": [],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T21:09:25.054097Z",
     "start_time": "2024-09-16T21:09:25.039074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# Função de treinamento\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, device):\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "                output = model(x_batch)\n",
    "                val_loss += criterion(output, y_batch).item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            logging.info(f\"Early stopping ativado na época {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model"
   ],
   "id": "4bbba2f5ba37fc6b",
   "outputs": [],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T21:09:25.148131Z",
     "start_time": "2024-09-16T21:09:25.134088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Desnormalização\n",
    "def inverse_transform_data(normalized_data, scaler, num_features):\n",
    "    # Create a dummy array with the correct number of features\n",
    "    dummy_array = np.zeros((len(normalized_data), num_features))\n",
    "    \n",
    "    # Put the normalized data in the first column (assuming it's PM2.5)\n",
    "    dummy_array[:, 0] = normalized_data.flatten()\n",
    "    \n",
    "    # Apply the inverse transformation\n",
    "    denormalized_data = scaler.inverse_transform(dummy_array)\n",
    "    \n",
    "    # Return only the first column, which contains the data of interest\n",
    "    return denormalized_data[:, 0]"
   ],
   "id": "8e4137c8d442683a",
   "outputs": [],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T21:09:25.243194Z",
     "start_time": "2024-09-16T21:09:25.229676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return rmse, mse, mae, r2, mape"
   ],
   "id": "edec688fd92d1f19",
   "outputs": [],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T21:09:25.351942Z",
     "start_time": "2024-09-16T21:09:25.337429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    # Hiperparâmetros para otimização\n",
    "    num_lstm_layers = trial.suggest_int('num_lstm_layers', 1, 6)\n",
    "    hidden_sizes = [trial.suggest_int(f'hidden_size_{i}', 32, 256) for i in range(num_lstm_layers)]\n",
    "\n",
    "    num_mlp_layers = trial.suggest_int('num_mlp_layers', 1, 4)\n",
    "    mlp_sizes = [trial.suggest_int(f'mlp_size_{i}', 32, 256) for i in range(num_mlp_layers)]\n",
    "\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-2, log=True)\n",
    "    activation = trial.suggest_categorical('activation',\n",
    "                                           ['relu', 'leaky_relu', 'elu', 'sigmoid', 'swish', 'mish', 'gelu', 'tanh',\n",
    "                                            'softplus'])\n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    cv_scores = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(tscv.split(X_train)):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        # Normalize the data for each fold\n",
    "        scaler_fold = StandardScaler()\n",
    "        X_train_fold_scaled = scaler_fold.fit_transform(X_train_fold.reshape(-1, X_train_fold.shape[-1])).reshape(X_train_fold.shape)\n",
    "        X_val_fold_scaled = scaler_fold.transform(X_val_fold.reshape(-1, X_val_fold.shape[-1])).reshape(X_val_fold.shape)\n",
    "        \n",
    "        y_train_fold_scaled = scaler_fold.fit_transform(y_train_fold.reshape(-1, 1)).flatten()\n",
    "        y_val_fold_scaled = scaler_fold.transform(y_val_fold.reshape(-1, 1)).flatten()\n",
    "\n",
    "        # Convert to torch tensors and ensure they're float32\n",
    "        X_train_fold_tensor = torch.tensor(X_train_fold_scaled, dtype=torch.float32)\n",
    "        y_train_fold_tensor = torch.tensor(y_train_fold_scaled, dtype=torch.float32).unsqueeze(1)\n",
    "        X_val_fold_tensor = torch.tensor(X_val_fold_scaled, dtype=torch.float32)\n",
    "        y_val_fold_tensor = torch.tensor(y_val_fold_scaled, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "        train_dataset = TimeSeriesDataset(X_train_fold_tensor, y_train_fold_tensor)\n",
    "        val_dataset = TimeSeriesDataset(X_val_fold_tensor, y_val_fold_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "        model = LSTM_MLP(X_train_fold.shape[-1], hidden_sizes, mlp_sizes, activation, dropout).to(device)\n",
    "        model = model.float()  # Ensure model parameters are float32\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        num_epochs = 1000\n",
    "        early_stopping_patience = 50\n",
    "\n",
    "        model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, early_stopping_patience, device)\n",
    "        \n",
    "        model.eval()\n",
    "        val_predictions = []\n",
    "        val_true = []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "                output = model(x_batch)\n",
    "                val_predictions.extend(output.cpu().numpy())\n",
    "                val_true.extend(y_batch.cpu().numpy())\n",
    "\n",
    "        val_predictions = scaler_fold.inverse_transform(np.array(val_predictions).reshape(-1, 1)).flatten()\n",
    "        val_true = scaler_fold.inverse_transform(np.array(val_true).reshape(-1, 1)).flatten()\n",
    "\n",
    "        rmse, mse, mae, r2, mape = calculate_metrics(val_true, val_predictions)\n",
    "        cv_scores.append(rmse)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\\nMAPE: {mape:.4f}\\nRMSE: {rmse:.4f}\\nR²: {r2:.4f}\\nMAE: {mae:.4f}\")\n",
    "\n",
    "    mean_rmse = np.mean(cv_scores)\n",
    "    std_rmse = np.std(cv_scores)\n",
    "\n",
    "    print(f\"Mean RMSE: {mean_rmse:.4f} (±{std_rmse:.4f})\")\n",
    "    \n",
    "    trial.set_user_attr(\"mean_RMSE\", mean_rmse)\n",
    "    trial.set_user_attr(\"std_RMSE\", std_rmse)\n",
    "\n",
    "    return mean_rmse\n",
    "\n"
   ],
   "id": "5b1ce00606d3df1",
   "outputs": [],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-16T21:09:25.448210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Após a otimização, imprimir os melhores resultados\n",
    "best_trial = study.best_trial\n",
    "print(\"Best trial:\\nValue (Validation Loss):\", best_trial.value + \"\\nMAPE:\", best_trial.user_attrs['MAPE'], \"\\nRMSE:\",\n",
    "      best_trial.user_attrs['RMSE'], \"\\nR²:\", best_trial.user_attrs['R2'])\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ],
   "id": "67359f0480b62406",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-16 18:09:25,454] A new study created in memory with name: no-name-6f5f39f5-a827-4db2-a4d0-3ae5caa68d80\n",
      "C:\\dev\\scripts\\pm25-plots\\venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "MAPE: 142.0558\n",
      "RMSE: 0.8421\n",
      "R²: 0.2743\n",
      "MAE: 0.5285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\scripts\\pm25-plots\\venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "[W 2024-09-16 18:20:02,361] Trial 0 failed with parameters: {'num_lstm_layers': 1, 'hidden_size_0': 130, 'num_mlp_layers': 1, 'mlp_size_0': 215, 'batch_size': 256, 'learning_rate': 1.029451891233886e-06, 'activation': 'mish', 'dropout': 0.3467597314638105, 'weight_decay': 0.0003016173043304161} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\scripts\\pm25-plots\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\portes\\AppData\\Local\\Temp\\ipykernel_10020\\1901531898.py\", line 51, in objective\n",
      "    model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, early_stopping_patience, device)\n",
      "  File \"C:\\Users\\portes\\AppData\\Local\\Temp\\ipykernel_10020\\3004087354.py\", line 22, in train_model\n",
      "    loss.backward()\n",
      "  File \"C:\\dev\\scripts\\pm25-plots\\venv\\lib\\site-packages\\torch\\_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"C:\\dev\\scripts\\pm25-plots\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"C:\\dev\\scripts\\pm25-plots\\venv\\lib\\site-packages\\torch\\autograd\\graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "[W 2024-09-16 18:20:02,362] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[152], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m torch\u001B[38;5;241m.\u001B[39mbackends\u001B[38;5;241m.\u001B[39mcudnn\u001B[38;5;241m.\u001B[39mbenchmark \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m      3\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mminimize\u001B[39m\u001B[38;5;124m'\u001B[39m, sampler\u001B[38;5;241m=\u001B[39moptuna\u001B[38;5;241m.\u001B[39msamplers\u001B[38;5;241m.\u001B[39mTPESampler())\n\u001B[1;32m----> 4\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Após a otimização, imprimir os melhores resultados\u001B[39;00m\n\u001B[0;32m      7\u001B[0m best_trial \u001B[38;5;241m=\u001B[39m study\u001B[38;5;241m.\u001B[39mbest_trial\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\lib\\site-packages\\optuna\\study\\study.py:475\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    373\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[0;32m    374\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    375\u001B[0m     func: ObjectiveFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    382\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    383\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    384\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[0;32m    385\u001B[0m \n\u001B[0;32m    386\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    473\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[0;32m    474\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 475\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    476\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    477\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    478\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    479\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    480\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    481\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    482\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    483\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    484\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    485\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001B[0m, in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     62\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 63\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     64\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     76\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    157\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 160\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    162\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[0;32m    164\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    241\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    243\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    244\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    246\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[0;32m    247\u001B[0m ):\n\u001B[1;32m--> 248\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[0;32m    196\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 197\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    198\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    199\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[0;32m    200\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[1;32mIn[151], line 51\u001B[0m, in \u001B[0;36mobjective\u001B[1;34m(trial)\u001B[0m\n\u001B[0;32m     48\u001B[0m num_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1000\u001B[39m\n\u001B[0;32m     49\u001B[0m early_stopping_patience \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m50\u001B[39m\n\u001B[1;32m---> 51\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stopping_patience\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     53\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m     54\u001B[0m val_predictions \u001B[38;5;241m=\u001B[39m []\n",
      "Cell \u001B[1;32mIn[148], line 22\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, device)\u001B[0m\n\u001B[0;32m     19\u001B[0m output \u001B[38;5;241m=\u001B[39m model(x_batch)\n\u001B[0;32m     20\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(output, y_batch)\n\u001B[1;32m---> 22\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m clip_grad_norm_(model\u001B[38;5;241m.\u001B[39mparameters(), max_norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.0\u001B[39m)\n\u001B[0;32m     24\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\lib\\site-packages\\torch\\_tensor.py:521\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    512\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    513\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    514\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    519\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    520\u001B[0m     )\n\u001B[1;32m--> 521\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:289\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    284\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    286\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 289\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    290\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    291\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    292\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    293\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    294\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    295\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    296\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    297\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\dev\\scripts\\pm25-plots\\venv\\lib\\site-packages\\torch\\autograd\\graph.py:769\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    767\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    768\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 769\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    770\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    771\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    772\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    773\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 152
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_params = study.best_params\n",
    "logging.info(f\"Melhores hiperparâmetros: {best_params}\")\n",
    "\n",
    "# Treinamento final com os melhores hiperparâmetros\n",
    "best_hidden_sizes = [best_params[f'hidden_size_{i}'] for i in range(best_params['num_layers'])]\n",
    "best_batch_size = best_params['batch_size']\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "val_dataset = TimeSeriesDataset(X_val, y_val)\n",
    "test_dataset = TimeSeriesDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_batch_size, shuffle=False, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=best_batch_size, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "final_model = LSTM_MLP(len(colunas_selecionadas), best_hidden_sizes, best_params['activation'],\n",
    "                       best_params['dropout']).to(\n",
    "    device)\n",
    "optimizer = torch.optim.AdamW(final_model.parameters(), lr=best_params['learning_rate'])\n",
    "criterion = nn.HuberLoss()\n",
    "\n",
    "num_epochs = 1000\n",
    "patience = 50\n",
    "\n",
    "final_model = train_model(final_model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, device)\n",
    "\n",
    "# Salvar o modelo final\n",
    "torch.save(final_model.state_dict(), f'../models/best_model_optuna_{data_hoje}.pth')\n",
    "\n",
    "\n",
    "# Avaliação final\n",
    "def evaluate(model, dataloader):\n",
    "    predictions = []\n",
    "    actual = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "            output = model(x_batch)\n",
    "            predictions.extend(output.cpu().numpy().flatten())\n",
    "            actual.extend(y_batch.cpu().numpy().flatten())\n",
    "    return np.array(predictions), np.array(actual)\n",
    "\n",
    "\n",
    "train_predictions, train_actual = evaluate(final_model, train_loader)\n",
    "val_predictions, val_actual = evaluate(final_model, val_loader)\n",
    "test_predictions, test_actual = evaluate(final_model, test_loader)"
   ],
   "id": "99647cbd636d47cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Desnormalização das previsões e valores reais\n",
    "train_predictions = inverse_transform_data(train_predictions)\n",
    "val_predictions = inverse_transform_data(val_predictions)\n",
    "test_predictions = inverse_transform_data(test_predictions)\n",
    "\n",
    "# Para os valores reais, precisamos garantir que estamos usando os dados originais não normalizados\n",
    "train_actual = df_imputed['PM2.5'].values[:len(train_predictions)]\n",
    "val_actual = df_imputed['PM2.5'].values[len(train_predictions):len(train_predictions) + len(val_predictions)]\n",
    "test_actual = df_imputed['PM2.5'].values[-len(test_predictions):]\n",
    "\n",
    "# Calcular métricas\n",
    "train_rmse, train_mse, train_mae, train_r2, train_mape = calculate_metrics(train_actual, train_predictions)\n",
    "val_rmse, val_mse, val_mae, val_r2, val_mape = calculate_metrics(val_actual, val_predictions)\n",
    "test_rmse, test_mse, test_mae, test_r2, test_mape = calculate_metrics(test_actual, test_predictions)\n",
    "\n",
    "# Logging dos resultados\n",
    "logging.info(\n",
    "    f\"Métricas de Treino: RMSE={train_rmse:.4f}, MSE={train_mse:.4f}, MAE={train_mae:.4f}, R2={train_r2:.4f}, MAPE={train_mape:.4f}\")\n",
    "logging.info(\n",
    "    f\"Métricas de Validação: RMSE={val_rmse:.4f}, MSE={val_mse:.4f}, MAE={val_mae:.4f}, R2={val_r2:.4f}, MAPE={val_mape:.4f}\")\n",
    "logging.info(\n",
    "    f\"Métricas de Teste: RMSE={test_rmse:.4f}, MSE={test_mse:.4f}, MAE={test_mae:.4f}, R2={test_r2:.4f}, MAPE={test_mape:.4f}\")\n",
    "\n",
    "print(\n",
    "    f\"Métricas de Treino: RMSE={test_rmse:.4f}, MSE={test_mse:.4f}, MAE={test_mae:.4f}, R2={test_r2:.4f}, MAPE={test_mape:.4f}\")"
   ],
   "id": "8ed03d304545ce81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Log das métricas finais\n",
    "logging.info(\"\\nMétricas finais:\")\n",
    "logging.info(\"Treinamento - RMSE: {:.4f}, MSE: {:.4f}, MAE: {:.4f}, R²: {:.4f}\".format(train_rmse, train_mse, train_mae,\n",
    "                                                                                       train_r2))\n",
    "logging.info(\n",
    "    \"Validação - RMSE: {:.4f}, MSE: {:.4f}, MAE: {:.4f}, R²: {:.4f}\".format(val_rmse, val_mse, val_mae, val_r2))\n",
    "logging.info(\n",
    "    \"Teste - RMSE: {:.4f}, MSE: {:.4f}, MAE: {:.4f}, R²: {:.4f}\".format(test_rmse, test_mse, test_mae, test_r2))\n",
    "\n",
    "# Plotagem dos resultados\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_actual, label='Actual PM2.5')\n",
    "plt.plot(train_predictions, label='Predicted PM2.5')\n",
    "plt.title('Treinamento: PM2.5 Real vs Previsto')\n",
    "plt.xlabel('Hora')\n",
    "plt.ylabel('PM2.5')\n",
    "plt.legend()\n",
    "plt.savefig(f'../plots/{data_hoje}/lstm_optuna_train_{data_hoje}.png')\n"
   ],
   "id": "60faf0cdcf264037",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "train_dates = shifted_df.index[:len(train_actual)]\n",
    "val_dates = shifted_df.index[len(train_actual):len(train_actual) + len(val_actual)]\n",
    "test_dates = shifted_df.index[-len(test_actual):]\n",
    "\n",
    "\n",
    "def plot_results(actual, predicted, dates, title, filename):\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.plot(dates, actual, label='Real', color='blue')\n",
    "    plt.plot(dates, predicted, label='Previsto', color='red')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Data')\n",
    "    plt.ylabel('PM2.5')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))  # Mostrar a cada 3 meses\n",
    "\n",
    "    plt.gcf().autofmt_xdate()  # Rotacionar e alinhar os rótulos de data\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../plots/{data_hoje}/{filename}_{data_hoje}.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "plot_results(train_actual, train_predictions, train_dates, 'Treinamento: PM2.5 Real vs Previsto', 'lstm_optuna_train')\n",
    "plot_results(val_actual, val_predictions, val_dates, 'Validação: PM2.5 Real vs Previsto', 'lstm_optuna_val')\n",
    "plot_results(test_actual, test_predictions, test_dates, 'Teste: PM2.5 Real vs Previsto', 'lstm_optuna_test')\n",
    "\n",
    "fim_execucao = pd.Timestamp.now()\n",
    "tempo_execucao = fim_execucao - inicio_execucao\n",
    "logging.info(f\"\\nExecução finalizada em {fim_execucao}\")\n",
    "logging.info(f\"Tempo total de execução: {tempo_execucao}\")"
   ],
   "id": "19edab1f2a08d516",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_results_by_month(actual, predicted, dates, title_prefix, filename_prefix):\n",
    "    df = pd.DataFrame({'date': dates, 'actual': actual, 'predicted': predicted})\n",
    "    df.set_index('date', inplace=True)\n",
    "\n",
    "    grouped = df.groupby(pd.Grouper(freq='M'))\n",
    "\n",
    "    for name, group in grouped:\n",
    "        if len(group) > 0:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(group.index, group['actual'], label='Real', color='blue')\n",
    "            plt.plot(group.index, group['predicted'], label='Previsto', color='red')\n",
    "\n",
    "            month_year = name.strftime('%B %Y')\n",
    "            plt.title(f'{title_prefix} - {month_year}')\n",
    "            plt.xlabel('Data')\n",
    "            plt.ylabel('PM2.5')\n",
    "            plt.legend()\n",
    "\n",
    "            plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d-%m'))\n",
    "            plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=5))\n",
    "\n",
    "            plt.gcf().autofmt_xdate()  # Rotacionar e alinhar os rótulos de data\n",
    "            plt.tight_layout()\n",
    "\n",
    "            month_filename = f'{filename_prefix}_{name.strftime(\"%Y_%m\")}_{data_hoje}.png'\n",
    "            plt.savefig(f'../plots/{data_hoje}/{month_filename}')\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "plot_results_by_month(train_actual, train_predictions, train_dates, 'Treinamento: PM2.5 Real vs Previsto',\n",
    "                      'lstm_optuna_train')\n",
    "plot_results_by_month(val_actual, val_predictions, val_dates, 'Validação: PM2.5 Real vs Previsto', 'lstm_optuna_val')\n",
    "plot_results_by_month(test_actual, test_predictions, test_dates, 'Teste: PM2.5 Real vs Previsto', 'lstm_optuna_test')"
   ],
   "id": "5d311845f2a60318",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
